
Classical Conditioning for Pain: The Development of a Customized Single-Case Experimental DesignKeywords: single-case, classical conditioning, pain, randomization test, statistical power.Take-Home MessageWe wanted to design a single-case experiment to test whether classical conditioning can influence pain thresholds. We settled on a customized AB phase design for which we ran pilot tests and a power study. The results indicated that this single-case design can be used to test our hypothesis.AbstractSingle-case experiments are increasingly popular in the behavioral sciences. Due to their flexibility, single-case designs can be customized to test a variety of experimental hypotheses. We were interested in using a single-case experimental approach to test whether pain thresholds can be influenced by Pavlovian classical conditioning. Following the example of earlier studies into this topic, we planned to measure whether participants would more frequently report specific electrocutaneous stimuli as painful when they were presented with specific vibrotactile stimuli that had previously been associated with painful electrocutaneous stimuli. First, we decided on a mean difference effect size measure derived from the Sensation and Pain Rating Scale ratings for the electrocutaneous stimuli provided by the participants. Next, we discussed several possible single-case designs and evaluated their benefits and shortcomings. Then, we ran pilot tests with a few participants based on the possible single-case designs. We also conducted a simulation study to estimate the power of a randomization test to test our hypothesis using different values for effect size, number of participants, and number of measurements. Finally, we decided on a sequentially replicated AB phase design with 30 participants based on the results from the pilot tests and the power study. We plan to implement this single-case design in a future experiment to test our hypothesis. PurposeIn this manuscript, our purpose is to describe how we used a trial and error approach to design a customized single-case experiment (SCE) to test the effect of classical conditioning on pain thresholds. We hope that this information helps readers who plan to implement an SCE in better understanding the steps involved and possible challenges. We wish to focus on using the flexible nature of SCEs to adapt to the requirements of the experiment. We also wish to highlight the necessity of exploring various available statistical methods and statistical power requirements for these methods prior to starting the experiment. Finally, we demonstrate how SCEs can serve as a viable avenue for pilot-testing new therapies and treatments at a small scale before implementing larger scale studies.IntroductionClassical ConditioningPersistent pain—pain that is still felt after bodily tissue has healed—is a major healthcare problem that is poorly understood and, consequently, difficult to treat effectively ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1016/j.ejpain.2005.06.009","ISSN":"1090-3801 (Print)","PMID":"16095934","abstract":"This large scale computer-assisted telephone survey was undertaken to explore the prevalence, severity, treatment and impact of chronic pain in 15 European countries and Israel. Screening interviews identified respondents aged 18 years with chronic pain for in-depth interviews. 19% of 46,394 respondents willing to participate (refusal rate 46%) had suffered pain for 6 months, had experienced pain in the last month and several times during the last week. Their pain intensity was 5 on a 10-point Numeric Rating Scale (NRS) (1 = no pain, 10 = worst pain imaginable) during last episode of pain. In-depth interviews with 4839 respondents with chronic pain (about 300 per country) showed: 66% had moderate pain (NRS = 5-7), 34% had severe pain (NRS = 8-10), 46% had constant pain, 54% had intermittent pain. 59% had suffered with pain for two to 15 years, 21% had been diagnosed with depression because of their pain, 61% were less able or unable to work outside the home, 19% had lost their job and 13% had changed jobs because of their pain. 60% visited their doctor about their pain 2-9 times in the last six months. Only 2% were currently treated by a pain management specialist. One-third of the chronic pain sufferers were currently not being treated. Two-thirds used non-medication treatments, e.g,. massage (30%), physical therapy (21%), acupuncture (13%). Almost half were taking non-prescription analgesics; 'over the counter' (OTC) NSAIDs (55%), paracetamol (43%), weak opioids (13%). Two-thirds were taking prescription medicines: NSAIDs (44%), weak opioids (23%), paracetamol (18%), COX-2 inhibitors (1-36%), and strong opioids (5%). Forty percent had inadequate management of their pain. Interesting differences between countries were observed, possibly reflecting differences in cultural background and local traditions in managing chronic pain. CONCLUSIONS: Chronic pain of moderate to severe intensity occurs in 19% of adult Europeans, seriously affecting the quality of their social and working lives. Very few were managed by pain specialists and nearly half received inadequate pain management. Although differences were observed between the 16 countries, we have documented that chronic pain is a major health care problem in Europe that needs to be taken more seriously.","author":[{"dropping-particle":"","family":"Breivik","given":"Harald","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Collett","given":"Beverly","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Ventafridda","given":"Vittorio","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Cohen","given":"Rob","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Gallacher","given":"Derek","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"European journal of pain (London, England)","id":"ITEM-1","issue":"4","issued":{"date-parts":[["2006","5"]]},"language":"eng","page":"287-333","publisher-place":"England","title":"Survey of chronic pain in Europe: Prevalence, impact on daily life, and treatment.","type":"article-journal","volume":"10"},"uris":["http://www.mendeley.com/documents/?uuid=792ec57c-b8b4-4772-a648-6727255d4af5"]},{"id":"ITEM-2","itemData":{"DOI":"10.1016/j.jpain.2008.05.005","ISSN":"1528-8447 (Electronic)","PMID":"18602869","abstract":"Although there is a growing body of research concerning the prevalence and correlates of chronic pain conditions and their association with mental disorders, cross-national research on age and gender differences is limited. The present study reports the prevalence by age and gender of common chronic pain conditions (headache, back or neck pain, arthritis or joint pain, and other chronic pain) in 10 developed and 7 developing countries and their association with the spectrum of both depressive and anxiety disorders. It draws on data from 18 general adult population surveys using a common survey questionnaire (N = 42,249). Results show that age-standardized prevalence of chronic pain conditions in the previous 12 months was 37.3% in developed countries and 41.1% in developing countries, with back pain and headache being somewhat more common in developing than developed countries. After controlling for comorbid chronic physical diseases, several findings were consistent across developing and developed countries. There was a higher prevalence of chronic pain conditions among females and older persons; and chronic pain was similarly associated with depression-anxiety spectrum disorders in developed and developing countries. However, the large majority of persons reporting chronic pain did not meet criteria for depression or anxiety disorder. We conclude that common pain conditions affect a large percentage of persons in both developed and developing countries. PERSPECTIVE: Chronic pain conditions are common in both developed and developing countries. Overall, the prevalence of pain is greater among females and among older persons. Although most persons reporting pain do not meet criteria for a depressive or anxiety disorder, depression/anxiety spectrum disorders are associated with pain in both developed and developing countries.","author":[{"dropping-particle":"","family":"Tsang","given":"Adley","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Korff","given":"Michael","non-dropping-particle":"Von","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Lee","given":"Sing","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Alonso","given":"Jordi","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Karam","given":"Elie","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Angermeyer","given":"Matthias C","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Borges","given":"Guilherme Luiz Guimaraes","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Bromet","given":"Evelyn J","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Demytteneare","given":"K","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Girolamo","given":"Giovanni","non-dropping-particle":"de","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Graaf","given":"Ron","non-dropping-particle":"de","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Gureje","given":"Oye","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Lepine","given":"Jean-Pierre","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Haro","given":"Josep Maria","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Levinson","given":"Daphna","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Oakley Browne","given":"Mark A","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Posada-Villa","given":"Jose","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Seedat","given":"Soraya","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Watanabe","given":"Makoto","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"The Journal of Pain","id":"ITEM-2","issue":"10","issued":{"date-parts":[["2008","10"]]},"language":"eng","page":"883-891","publisher-place":"United States","title":"Common chronic pain conditions in developed and developing countries: Gender and age differences and comorbidity with depression-anxiety disorders.","type":"article-journal","volume":"9"},"uris":["http://www.mendeley.com/documents/?uuid=c5ee4e4e-0c70-4c3f-a17f-d31c1bfc5984"]},{"id":"ITEM-3","itemData":{"DOI":"10.1136/bmj.b3829","abstract":"Objectives To describe the course of chronic low back pain in an inception cohort and to identify prognostic markers at the onset of chronicity.Design Inception cohort study with one year follow-up.Setting Primary care clinics in Sydney, Australia.Participants The study sample was a subcohort of an inception cohort of 973 consecutive patients presenting to primary care with acute low back pain (&amp;lt;2 weeks’ duration). 406 participants whose pain persisted for three months formed the inception cohort of patients with chronic low back pain. Main outcome measures Outcomes and putative predictors measured at initial presentation, onset of chronicity (study entry), and follow-up at nine and 12 months. Recovery was determined from measures of pain intensity, disability, and work status. The association between potential prognostic factors and time to recovery was modelled with Cox regression.Results Completeness of follow-up was 97% of total person time for all outcomes. The cumulative probability of being pain-free was 35% at nine months and 42% at 12 months and for complete recovery was 35% at nine months and 41% at 12 months. Of the 259 participants who had not recovered from pain related disability at entry to the chronic study, 47% had recovered by 12 months. Previous sick leave due to low back pain, high disability levels or high pain intensity at onset of chronicity, low levels of education, greater perceived risk of persistent pain, and being born outside Australia were associated with delayed recovery.Conclusion More than one third of patients with recent onset, non-radicular chronic low back pain recover within 12 months. The prognosis is less favourable for those who have taken previous sick leave for low back pain, have high disability levels or high pain intensity at onset of chronic low back pain, have lower education, perceive themselves as having a high risk of persistent pain, and were born outside Australia.","author":[{"dropping-particle":"","family":"Costa","given":"Luciola da C Menezes","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Maher","given":"Christopher G","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"McAuley","given":"James H","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Hancock","given":"Mark J","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Herbert","given":"Robert D","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Refshauge","given":"Kathryn M","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Henschke","given":"Nicholas","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"BMJ","id":"ITEM-3","issued":{"date-parts":[["2009","10","6"]]},"page":"b3829","title":"Prognosis for patients with chronic low back pain: Inception cohort study","type":"article-journal","volume":"339"},"uris":["http://www.mendeley.com/documents/?uuid=5b919bd1-a70e-4f8c-a038-e4277c5e2f31"]},{"id":"ITEM-4","itemData":{"DOI":"10.1016/S0140-6736(18)30489-6","ISSN":"0140-6736","author":[{"dropping-particle":"","family":"Foster","given":"Nadine E","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Anema","given":"Johannes R","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Cherkin","given":"Dan","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Chou","given":"Roger","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Cohen","given":"Steven P","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Gross","given":"Douglas P","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Ferreira","given":"Paulo H","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Fritz","given":"Julie M","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Koes","given":"Bart W","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Peul","given":"Wilco","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Turner","given":"Judith A","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Maher","given":"Chris G","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Buchbinder","given":"Rachelle","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Hartvigsen","given":"Jan","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Cherkin","given":"Dan","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Foster","given":"Nadine E","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Maher","given":"Chris G","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Underwood","given":"Martin","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Tulder","given":"Maurits","non-dropping-particle":"van","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Anema","given":"Johannes R","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Chou","given":"Roger","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Cohen","given":"Stephen P","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Menezes Costa","given":"Lucíola","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Croft","given":"Peter","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Ferreira","given":"Manuela","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Ferreira","given":"Paulo H","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Fritz","given":"Julie M","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Genevay","given":"Stéphane","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Gross","given":"Douglas P","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Hancock","given":"Mark J","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Hoy","given":"Damian","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Karppinen","given":"Jaro","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Koes","given":"Bart W","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Kongsted","given":"Alice","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Louw","given":"Quinette","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Öberg","given":"Birgitta","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Peul","given":"Wilco C","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Pransky","given":"Glenn","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Schoene","given":"Mark","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Sieper","given":"Joachim","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Smeets","given":"Rob J","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Turner","given":"Judith A","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Woolf","given":"Anthony","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"The Lancet","id":"ITEM-4","issue":"10137","issued":{"date-parts":[["2018","6","9"]]},"note":"doi: 10.1016/S0140-6736(18)30489-6","page":"2368-2383","publisher":"Elsevier","title":"Prevention and treatment of low back pain: Evidence, challenges, and promising directions","type":"article-journal","volume":"391"},"uris":["http://www.mendeley.com/documents/?uuid=aa835aca-e6c7-46e0-bcfc-0f6815599023"]},{"id":"ITEM-5","itemData":{"DOI":"10.1097/j.pain.0000000000001384","ISSN":"18726623","PMID":"30586067","abstract":"Chronic pain is a major source of suffering. It interferes with daily functioning and often is accompanied by distress. Yet, in the International Classification of Diseases, chronic pain diagnoses are not represented systematically. The lack of appropriate codes renders accurate epidemiological investigations difficult and impedes health policy decisions regarding chronic pain such as adequate financing of access to multimodal pain management. In cooperation with the WHO, an IASP Working Group has developed a classification system that is applicable in a wide range of contexts, including pain medicine, primary care, and low-resource environments. Chronic pain is defined as pain that persists or recurs for more than 3 months. In chronic pain syndromes, pain can be the sole or a leading complaint and requires special treatment and care. In conditions such as fibromyalgia or nonspecific low-back pain, chronic pain may be conceived as a disease in its own right; in our proposal, we call this subgroup \"chronic primary pain.\" In 6 other subgroups, pain is secondary to an underlying disease: chronic cancer-related pain, chronic neuropathic pain, chronic secondary visceral pain, chronic posttraumatic and postsurgical pain, chronic secondary headache and orofacial pain, and chronic secondary musculoskeletal pain. These conditions are summarized as \"chronic secondary pain\" where pain may at least initially be conceived as a symptom. Implementation of these codes in the upcoming 11th edition of International Classification of Diseases will lead to improved classification and diagnostic coding, thereby advancing the recognition of chronic pain as a health condition in its own right.","author":[{"dropping-particle":"","family":"Treede","given":"Rolf Detlef","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Rief","given":"Winfried","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Barke","given":"Antonia","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Aziz","given":"Qasim","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Bennett","given":"Michael I.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Benoliel","given":"Rafael","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Cohen","given":"Milton","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Evers","given":"Stefan","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Finnerup","given":"Nanna B.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"First","given":"Michael B.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Giamberardino","given":"Maria Adele","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Kaasa","given":"Stein","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Korwisi","given":"Beatrice","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Kosek","given":"Eva","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Lavand'Homme","given":"Patricia","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Nicholas","given":"Michael","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Perrot","given":"Serge","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Scholz","given":"Joachim","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Schug","given":"Stephan","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Smith","given":"Blair H.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Svensson","given":"Peter","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Vlaeyen","given":"Johan W.S.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Wang","given":"Shuu Jiun","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Pain","id":"ITEM-5","issue":"1","issued":{"date-parts":[["2019"]]},"page":"19-27","title":"Chronic pain as a symptom or a disease: The IASP classification of chronic pain for the International Classification of Diseases (ICD-11)","type":"article-journal","volume":"160"},"uris":["http://www.mendeley.com/documents/?uuid=e5f5e7f7-4b64-48a9-9509-3537140e18bd"]}],"mendeley":{"formattedCitation":"(Breivik et al., 2006; Costa et al., 2009; Foster et al., 2018; Treede et al., 2019; Tsang et al., 2008)","plainTextFormattedCitation":"(Breivik et al., 2006; Costa et al., 2009; Foster et al., 2018; Treede et al., 2019; Tsang et al., 2008)","previouslyFormattedCitation":"(Breivik et al., 2006; Costa et al., 2009; Foster et al., 2018; Treede et al., 2019; Tsang et al., 2008)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Breivik et al., 2006; Costa et al., 2009; Foster et al., 2018; Treede et al., 2019; Tsang et al., 2008). While there are key models that go some way towards explaining how pain can persist without active tissue damage ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1038/306686a0","ISSN":"0028-0836 (Print)","PMID":"6656869","abstract":"Noxious skin stimuli which are sufficiently intense to produce tissue injury, characteristically generate prolonged post-stimulus sensory disturbances that include continuing pain, an increased sensitivity to noxious stimuli and pain following innocuous stimuli. This could result from either a reduction in the thresholds of skin nociceptors (sensitization) or an increase in the excitability of the central nervous system so that normal inputs now evoke exaggerated responses. Because sensitization of peripheral receptors occurs following injury, a peripheral mechanism is widely held to be responsible for post-injury hypersensitivity. To investigate this I have now developed an animal model where changes occur in the threshold and responsiveness of the flexor reflex following peripheral injury that are analogous to the sensory changes found in man. Electrophysiological analysis of the injury-induced increase in excitability of the flexion reflex shows that it in part arises from changes in the activity of the spinal cord. The long-term consequences of noxious stimuli result, therefore, from central as well as from peripheral changes.","author":[{"dropping-particle":"","family":"Woolf","given":"Clifford J","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Nature","id":"ITEM-1","issue":"5944","issued":{"date-parts":[["1983","12"]]},"language":"eng","page":"686-688","publisher-place":"England","title":"Evidence for a central component of post-injury pain hypersensitivity","type":"article-journal","volume":"306"},"uris":["http://www.mendeley.com/documents/?uuid=2ff72fa7-d045-4f16-b5a4-27d849b07504"]},{"id":"ITEM-2","itemData":{"DOI":"10.1016/j.pain.2010.09.030","ISSN":"1872-6623","abstract":"Nociceptor inputs can trigger a prolonged but reversible increase in the excitability and synaptic efficacy of neurons in central nociceptive pathways, the phenomenon of central sensitization. Central sensitization manifests as pain hypersensitivity, particularly dynamic tactile allodynia, secondary punctate or pressure hyperalgesia, aftersensations, and enhanced temporal summation. It can be readily and rapidly elicited in human volunteers by diverse experimental noxious conditioning stimuli to skin, muscles or viscera, and in addition to producing pain hypersensitivity, results in secondary changes in brain activity that can be detected by electrophysiological or imaging techniques. Studies in clinical cohorts reveal changes in pain sensitivity that have been interpreted as revealing an important contribution of central sensitization to the pain phenotype in patients with fibromyalgia, osteoarthritis, musculoskeletal disorders with generalized pain hypersensitivity, headache, temporomandibular joint disorders, dental pain, neuropathic pain, visceral pain hypersensitivity disorders and post-surgical pain. The comorbidity of those pain hypersensitivity syndromes that present in the absence of inflammation or a neural lesion, their similar pattern of clinical presentation and response to centrally acting analgesics, may reflect a commonality of central sensitization to their pathophysiology. An important question that still needs to be determined is whether there are individuals with a higher inherited propensity for developing central sensitization than others, and if so, whether this conveys an increased risk in both developing conditions with pain hypersensitivity, and their chronification. Diagnostic criteria to establish the presence of central sensitization in patients will greatly assist the phenotyping of patients for choosing treatments that produce analgesia by normalizing hyperexcitable central neural activity. We have certainly come a long way since the first discovery of activity-dependent synaptic plasticity in the spinal cord and the revelation that it occurs and produces pain hypersensitivity in patients. Nevertheless, discovering the genetic and environmental contributors to and objective biomarkers of central sensitization will be highly beneficial, as will additional treatment options to prevent or reduce this prevalent and promiscuous form of pain plasticity.","author":[{"dropping-particle":"","family":"Woolf","given":"Clifford J","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Pain","edition":"2010/10/18","id":"ITEM-2","issue":"3 Suppl","issued":{"date-parts":[["2011","3"]]},"language":"eng","page":"S2-S15","title":"Central sensitization: Implications for the diagnosis and treatment of pain","type":"article-journal","volume":"152"},"uris":["http://www.mendeley.com/documents/?uuid=5004bfd7-ce98-49c3-a1d7-db69173c7609"]},{"id":"ITEM-3","itemData":{"DOI":"10.1016/s0304-3959(99)00242-0","ISSN":"0304-3959 (Print)","PMID":"10781906","abstract":"In an attempt to explain how and why some individuals with musculoskeletal pain develop a chronic pain syndrome, Lethem et al. (Lethem J, Slade PD, Troup JDG, Bentley G. Outline of fear-avoidance model of exaggerated pain perceptions. Behav Res Ther 1983; 21: 401-408).ntroduced a so-called 'fear-avoidance' model. The central concept of their model is fear of pain. 'Confrontation' and 'avoidance' are postulated as the two extreme responses to this fear, of which the former leads to the reduction of fear over time. The latter, however, leads to the maintenance or exacerbation of fear, possibly generating a phobic state. In the last decade, an increasing number of investigations have corroborated and refined the fear-avoidance model. The aim of this paper is to review the existing evidence for the mediating role of pain-related fear, and its immediate and long-term consequences in the initiation and maintenance of chronic pain disability. We first highlight possible precursors of pain-related fear including the role negative appraisal of internal and external stimuli, negative affectivity and anxiety sensitivity may play. Subsequently, a number of fear-related processes will be discussed including escape and avoidance behaviors resulting in poor behavioral performance, hypervigilance to internal and external illness information, muscular reactivity, and physical disuse in terms of deconditioning and guarded movement. We also review the available assessment methods for the quantification of pain-related fear and avoidance. Finally, we discuss the implications of the recent findings for the prevention and treatment of chronic musculoskeletal pain. Although there are still a number of unresolved issues which merit future research attention, pain-related fear and avoidance appear to be an essential feature of the development of a chronic problem for a substantial number of patients with musculoskeletal pain.","author":[{"dropping-particle":"","family":"Vlaeyen","given":"Johan W.S.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Linton","given":"Steven J.","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Pain","id":"ITEM-3","issue":"3","issued":{"date-parts":[["2000","4"]]},"language":"eng","page":"317-332","publisher-place":"United States","title":"Fear-avoidance and its consequences in chronic musculoskeletal pain: A state of the art","type":"article-journal","volume":"85"},"uris":["http://www.mendeley.com/documents/?uuid=d17914e5-d158-4b59-bf0c-02cc8d5847d7"]},{"id":"ITEM-4","itemData":{"DOI":"10.1016/j.pain.2011.12.009","ISSN":"1872-6623 (Electronic)","PMID":"22321917","author":[{"dropping-particle":"","family":"Vlaeyen","given":"Johan W S","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Linton","given":"Steven J","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Pain","id":"ITEM-4","issue":"6","issued":{"date-parts":[["2012","6"]]},"language":"eng","page":"1144-1147","publisher-place":"United States","title":"Fear-avoidance model of chronic musculoskeletal pain: 12 years on","type":"article-journal","volume":"153"},"uris":["http://www.mendeley.com/documents/?uuid=915562a7-fdd4-4e8b-af71-f03a2d817e80"]}],"mendeley":{"formattedCitation":"(Vlaeyen & Linton, 2000, 2012; Woolf, 1983, 2011)","plainTextFormattedCitation":"(Vlaeyen & Linton, 2000, 2012; Woolf, 1983, 2011)","previouslyFormattedCitation":"(Vlaeyen & Linton, 2000, 2012; Woolf, 1983, 2011)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Vlaeyen & Linton, 2000, 2012; Woolf, 1983, 2011), certain pain presentations remain unexplained. The imprecision hypothesis was proposed to address these unexplained presentations, and is founded on the idea that pain can be modulated by pain-associated cues—specifically, via “classical conditioning” ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1016/j.pain.0000000000000014","ISSN":"1872-6623 (Electronic)","PMID":"25599298","author":[{"dropping-particle":"","family":"Moseley","given":"G Lorimer","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Vlaeyen","given":"Johan W S","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Pain","id":"ITEM-1","issue":"1","issued":{"date-parts":[["2015","1"]]},"language":"eng","page":"35-38","publisher-place":"United States","title":"Beyond nociception: The imprecision hypothesis of chronic pain","type":"article-journal","volume":"156"},"uris":["http://www.mendeley.com/documents/?uuid=82472e9e-f62a-40ff-8725-16ff06a01187"]}],"mendeley":{"formattedCitation":"(Moseley & Vlaeyen, 2015)","plainTextFormattedCitation":"(Moseley & Vlaeyen, 2015)","previouslyFormattedCitation":"(Moseley & Vlaeyen, 2015)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Moseley & Vlaeyen, 2015). Our study design builds on two previous experiments ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1016/j.jpain.2016.06.012","ISSN":"15288447","PMID":"27452948","abstract":"A classical conditioning framework is often used for clinical reasoning about pain that persists after tissue healing. However, experimental studies demonstrating classically conditioned pain in humans are lacking. The current study tested whether non-nociceptive somatosensory stimuli can come to modulate pain thresholds after being paired with painful nociceptive stimuli in healthy humans. We used a differential simultaneous conditioning paradigm in which one nonpainful vibrotactile conditioned stimulus (CS+) was simultaneously paired with an unconditioned painful laser stimulus, and another vibrotactile stimulus (CS−) was paired with a nonpainful laser stimulus. After acquisition, at-pain-threshold laser stimuli were delivered simultaneously with a CS+ or CS− vibrotactile stimulus. The primary outcome was the percentage of at-threshold laser stimuli that were reported as painful. The results were as expected: after conditioning, at-threshold laser trials paired with the CS+ were reported as painful more often, as more intense, and as more unpleasant than those paired with the CS−. This study provides new evidence that pain thresholds can be modulated via classical conditioning, even when the stimulus used to test the threshold cannot be anticipated. As such, it lays a critical foundation for further investigations of classical conditioning as a possible driver of persistent pain. Perspective This study provides new evidence that human pain thresholds can be influenced by non-nociceptive somatosensory stimuli, via a classical conditioning effect. As such, it lays a critical foundation for further investigations of classical conditioning as a possible driver of persistent pain.","author":[{"dropping-particle":"","family":"Madden","given":"Victoria J.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Bellan","given":"Valeria","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Russek","given":"Leslie N.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Camfferman","given":"Danny","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Vlaeyen","given":"Johan W.S.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Moseley","given":"G. Lorimer","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Journal of Pain","id":"ITEM-1","issue":"10","issued":{"date-parts":[["2016"]]},"page":"1105-1115","publisher":"Elsevier Inc","title":"Pain by association? Experimental modulation of human pain thresholds using classical conditioning","type":"article-journal","volume":"17"},"uris":["http://www.mendeley.com/documents/?uuid=98eecab5-9592-4297-99e7-e53ecc3d3f5e"]},{"id":"ITEM-2","itemData":{"DOI":"10.7717/peerj.6486","ISSN":"21678359","abstract":"Background: Classical conditioning has frequently been shown to be capable of evoking fear of pain and avoidance behavior in the context of chronic pain. However, whether pain itself can be conditioned has rarely been investigated and remains a matter of debate. Therefore, the present study investigated whether pain threshold ratings can be modified by the presence of conditioned non-nociceptive sensory stimuli in healthy participant. Methods: In 51 healthy volunteers, pain threshold to electrocutaneous stimuli was determined prior to participation in a simultaneous conditioning paradigm. Participants underwent an acquisition phase in which one non-painful vibrotactile stimulus (CS+) was repeatedly paired with a painful electrocutaneous stimulus, whereas a second vibrotactile stimulus of the same quality and intensity (CS-) was paired with a non-painful electrocutaneous stimulus. Stimulation was provided on the lower back with close proximity between the conditioned stimulus and the unconditioned stimulus. In the test phase, electrocutaneous stimuli at the individually-set threshold intensity were simultaneously delivered together with either a CS+ or CS-. Pain intensity ratings were obtained after each trial; expectancy ratings were obtained after each block. The primary outcome was the percentage of test stimuli that were rated as painful. Results: Test stimuli were more likely to be rated as painful when they were paired with the CS+ than when they were paired with the CS-. This effect was not influenced by contingency awareness, nor by expectancies or mood states. Discussion: The findings support the notion that the judgement of an event being painful or non-painful can be influenced by classical conditioning and corroborate the possible role of associative learning in the development and maintenance of chronic pain.","author":[{"dropping-particle":"","family":"Traxler","given":"Juliane","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Madden","given":"Victoria J.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Moseley","given":"G. Lorimer","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Vlaeyen","given":"Johan W.S.","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"PeerJ","id":"ITEM-2","issue":"3","issued":{"date-parts":[["2019"]]},"page":"1-20","title":"Modulating pain thresholds through classical conditioning","type":"article-journal","volume":"2019"},"uris":["http://www.mendeley.com/documents/?uuid=c5bbffe6-5041-42cb-a91c-332b22183efe"]}],"mendeley":{"formattedCitation":"(Madden et al., 2016; Traxler et al., 2019)","plainTextFormattedCitation":"(Madden et al., 2016; Traxler et al., 2019)","previouslyFormattedCitation":"(Madden et al., 2016; Traxler et al., 2019)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Madden et al., 2016; Traxler et al., 2019), which followed a Pavlovian or “classical” conditioning design ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1037/11081-000","abstract":"Over a quarter of a century ago Pavlov began, \"after persistent deliberation,\" to study the activity of the higher parts of the brain by physiological methods, mainly through the use of his conditioned reflexes. This book shows the historical development of the subject from the very beginning to the present, and it contains most of the important facts which he has discovered. As the subject is a new and somewhat difficult one, the many repetitions in varying form will probably not be unwelcome to the reader. Because the facts and methods described in the following pages cover most of Pavlov's important work on conditioned reflexes, it seemed worth while to us to make the translation from the original Russian. (PsycINFO Database Record (c) 2016 APA, all rights reserved)","author":[{"dropping-particle":"","family":"Pavlov","given":"Ivan Petrovitch","non-dropping-particle":"","parse-names":false,"suffix":""}],"id":"ITEM-1","issued":{"date-parts":[["1928"]]},"number-of-pages":"414","publisher":"Liverwright Publishing Corporation","publisher-place":"New York, NY, US","title":"Lectures on conditioned reflexes: Twenty-five years of objective study of the higher nervous activity (behaviour) of animals.","type":"book"},"uris":["http://www.mendeley.com/documents/?uuid=2553402c-9189-4336-9dea-9de09db7afd8"]}],"mendeley":{"formattedCitation":"(Pavlov, 1928)","plainTextFormattedCitation":"(Pavlov, 1928)","previouslyFormattedCitation":"(Pavlov, 1928)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Pavlov, 1928) to test whether neutral but pain-associated cues can bias a participant’s decision about whether a stimulus is painful or non-painful. In the differential classical conditioning design used here, one neutral cue is paired with a painful electrocutaneous stimulus, while another neutral cue is paired with a non-painful electrocutaneous stimulus. It is expected that participants form associations between each cue and painfulness, such that subsequent perception of an ambiguous electrical stimulus is modified, dependent on the simultaneous presentation of one of the neutral cues.We set out to design an SCE to test this hypothesis. Due to the before (conditioning) and after (conditioning) structure of multiple observations required for each participant, SCE designs are perfectly suited for testing this hypothesis.Single-Case ExperimentsSCEs are experiments in which the effect of manipulating an independent variable is observed in a single entity ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"ISBN":"9780205474554","author":[{"dropping-particle":"","family":"Barlow","given":"D H","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Nock","given":"M K","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Hersen","given":"M","non-dropping-particle":"","parse-names":false,"suffix":""}],"edition":"3","id":"ITEM-1","issued":{"date-parts":[["2009"]]},"number-of-pages":"393","publisher":"Pearson/Allyn and Bacon","publisher-place":"Boston, MA","title":"Single case experimental designs: Strategies for studying behavior change","type":"book"},"uris":["http://www.mendeley.com/documents/?uuid=3f9cf20a-1f7e-4f61-b91c-a7cfa8573c37"]},{"id":"ITEM-2","itemData":{"ISBN":"978-0-19-534188-1 (Paperback)","abstract":"Single-case research has played an important role in developing and evaluating interventions that are designed to alter a particular facet of human functioning. Now thoroughly updated in its second edition, acclaimed author Alan Kazdin's Single-Case Research Designs provides a notable contrast to the quantitative methodology approach that pervades the biological and social sciences. While focusing on widely applicable methodologies for evaluating interventions—such as treatment, education, and psychotherapy using applied behavior analysis—this revised edition also encompasses a broader range of research areas that use single-case designs demonstrating the pertinence of this methodology in various disciplines, from psychology and medicine to business and industry. The following aspects are new to this edition; Offers new options in experimental design, presenting combinations of designs that increase the range of questions that can be asked about alternative interventions; Details the underlying rationale and methods of evaluating intervention effects through visual inspection in the area of data evaluation; Provides an expanded description of methods (e.g., assessment) and a greater range of examples; Includes an appendix at the end of the book to encourage discussion of the challenges, advances, and dilemmas of statistical evaluation and visual inspection in the design. This well-written, clear, and thoroughly updated text is ideal for practitioners, instructors, and students alike. (PsycINFO Database Record (c) 2016 APA, all rights reserved)","author":[{"dropping-particle":"","family":"Kazdin","given":"Alan E","non-dropping-particle":"","parse-names":false,"suffix":""}],"edition":"2","id":"ITEM-2","issued":{"date-parts":[["2011"]]},"number-of-pages":"xi, 452-xi, 452","publisher":"Oxford University Press","publisher-place":"New York, NY","title":"Single-case research designs: Methods for clinical and applied settings","type":"book"},"uris":["http://www.mendeley.com/documents/?uuid=0bf25535-0ac8-4a4e-9baf-8d687854b102"]}],"mendeley":{"formattedCitation":"(Barlow et al., 2009; Kazdin, 2011)","plainTextFormattedCitation":"(Barlow et al., 2009; Kazdin, 2011)","previouslyFormattedCitation":"(Barlow et al., 2009; Kazdin, 2011)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Barlow et al., 2009; Kazdin, 2011). Variables of interest in the entity, which is often a single participant, are measured repeatedly over a period of time with the purpose of establishing a causal relationship between the independent variable, commonly referred to as the treatment condition, and the observed entity. SCEs are increasingly popular in behavioral and educational sciences due to their flexibility, low cost, and focus on effects of the intervention in individual participants ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1016/j.jcbs.2013.10.002","ISBN":"22121447","ISSN":"2212-1447","abstract":"A single-case experimental design is a research design that can be used to evaluate the effect of an intervention for a single entity. There are two important schedules to include randomization into the design of single-case experiments: phase designs and alternation designs. We present these two schedules and provide a detailed example for each schedule. For both examples, we illustrate the use of a free software package that assists researchers in designing and analyzing single-case experiments using randomization tests. Furthermore, we discuss several additions (simultaneous and sequential replication designs; meta-analysis of single-case experimental studies) and alternatives (statistical and visual analysis methods).","author":[{"dropping-particle":"","family":"Heyvaert","given":"Mieke","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Journal of Contextual Behavioral Science","id":"ITEM-1","issue":"1","issued":{"date-parts":[["2014"]]},"page":"51-64","title":"Randomization tests for single-case experiments: State of the art, state of the science, and state of the application","type":"article-journal","volume":"3"},"uris":["http://www.mendeley.com/documents/?uuid=198ba9d4-5192-465e-95ce-823dacfeb34c"]}],"mendeley":{"formattedCitation":"(Heyvaert & Onghena, 2014b)","plainTextFormattedCitation":"(Heyvaert & Onghena, 2014b)","previouslyFormattedCitation":"(Heyvaert & Onghena, 2014b)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Heyvaert & Onghena, 2014b). SCEs may be preferable to group-based designs, where the existence or magnitude of the effect within an individual is more relevant than the average effect across a group of individuals. The lower cost and flexibility of SCEs also make them ideal for studying new theories and interventions, as is the case in this study ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1007/s40732-020-00402-5","ISSN":"2163-3452","abstract":"With the objective of increasing the magnitude of treatment effects in behavioral health, there is steadily growing interest in tailoring assessments and interventions to better match individual needs. This aligns with the central idea that behavior can be adequately understood by considering the unique characteristics of the individual and context. Thus, data collected at an individual level provides critical evidence that can be used to inform health care decisions, improve treatment, or refine theories. Yet, the majority of research in behavioral health is based on group-level analyses. Recent developments in the field of single-case experimental design (SCED) has provided new opportunities to utilize individual data. The present article provides a state-of-the art overview regarding key aspects of SCED, including a historical background to why and how SCED emerged, declined, and recently reemerged as well as methodological aspects such as design issues, challenges related to reliability and validity of repeated observations, innovations in visual and statistical analyses of individual data, strategies to deal with missing values, methodology to examine effect size, and approaches to summarize data from a large number of SCEDs using multilevel models and meta-analyses of replication data. Finally, the article discusses key concerns and actions needed to move the field forward.","author":[{"dropping-particle":"","family":"Vlaeyen","given":"Johan W S","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Wicksell","given":"Rikard K","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Simons","given":"Laura E","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Gentili","given":"Charlotte","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"De","given":"Tamal Kumar","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Tate","given":"Robyn L","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Vohra","given":"Sunita","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Punja","given":"Salima","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Linton","given":"Steven J","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Sniehotta","given":"Falko F","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"The Psychological Record","id":"ITEM-1","issued":{"date-parts":[["2020"]]},"page":"659–670","title":"From Boulder to Stockholm in 70 years: Single case experimental designs in clinical research","type":"article-journal","volume":"70"},"uris":["http://www.mendeley.com/documents/?uuid=8cbc9455-1fec-45a0-9f79-1b3c919a9263"]}],"mendeley":{"formattedCitation":"(Vlaeyen et al., 2020)","plainTextFormattedCitation":"(Vlaeyen et al., 2020)","previouslyFormattedCitation":"(Vlaeyen et al., 2020)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Vlaeyen et al., 2020).In SCEs, assignment of the treatment conditions to measurement occasions can be randomized to strengthen internal validity ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1037/a0017736","ISSN":"1082989X","abstract":"In recent years, single-case designs have increasingly been used to establish an empirical basis for evidence-based interventions and techniques in a variety of disciplines, including psychology and education. Although traditional single-case designs have typically not met the criteria for a randomized controlled trial relative to conventional multiple-participant experimental designs, there are procedures that can be adopted to create a randomized experiment in this class of experimental design. Our two major purposes in writing this article were (a) to review the various types of single-case design that have been and can be used in psychological and educational intervention research and (b) to incorporate randomized experimental schemes into these designs, thereby improving them so that investigators can draw more valid conclusions from their research. For each traditional single-case design type reviewed, we provide illustrations of how various forms of randomization can be introduced into the basic design structure. We conclude by recommending that traditional single-case intervention designs be transformed into more scientifically credible randomized single-case intervention designs whenever the research conditions under consideration permit. © 2010 American Psychological Association.","author":[{"dropping-particle":"","family":"Kratochwill","given":"T. R.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Levin","given":"Joel R","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Psychological Methods","id":"ITEM-1","issue":"2","issued":{"date-parts":[["2010"]]},"page":"124-144","title":"Enhancing the scientific credibility of single-case intervention research: Randomization to the rescue","type":"article-journal","volume":"15"},"uris":["http://www.mendeley.com/documents/?uuid=ddfbcc90-d048-4d65-9827-fac88001c360"]},{"id":"ITEM-2","itemData":{"DOI":"10.1080/00223980.1975.9923926","ISSN":"0022-3980","author":[{"dropping-particle":"","family":"Edgington","given":"Eugene S","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Journal of Psychology","id":"ITEM-2","issue":"1","issued":{"date-parts":[["1975","5","1"]]},"note":"Last updated - 2013-02-21","page":"57","publisher":"Journal Press, etc.","publisher-place":"Provincetown, Mass., etc.","title":"Randomization tests for one-subject operant experiments","type":"article-journal","volume":"90"},"uris":["http://www.mendeley.com/documents/?uuid=b8cbd2f4-cfe3-4ff2-81ed-267a4033f315"]}],"mendeley":{"formattedCitation":"(Edgington, 1975; Kratochwill & Levin, 2010)","plainTextFormattedCitation":"(Edgington, 1975; Kratochwill & Levin, 2010)","previouslyFormattedCitation":"(Edgington, 1975; Kratochwill & Levin, 2010)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Edgington, 1975; Kratochwill & Levin, 2010). Additionally, replication using multiple participants strengthens external validity and generalizability of the results ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1037/a0017736","ISSN":"1082989X","abstract":"In recent years, single-case designs have increasingly been used to establish an empirical basis for evidence-based interventions and techniques in a variety of disciplines, including psychology and education. Although traditional single-case designs have typically not met the criteria for a randomized controlled trial relative to conventional multiple-participant experimental designs, there are procedures that can be adopted to create a randomized experiment in this class of experimental design. Our two major purposes in writing this article were (a) to review the various types of single-case design that have been and can be used in psychological and educational intervention research and (b) to incorporate randomized experimental schemes into these designs, thereby improving them so that investigators can draw more valid conclusions from their research. For each traditional single-case design type reviewed, we provide illustrations of how various forms of randomization can be introduced into the basic design structure. We conclude by recommending that traditional single-case intervention designs be transformed into more scientifically credible randomized single-case intervention designs whenever the research conditions under consideration permit. © 2010 American Psychological Association.","author":[{"dropping-particle":"","family":"Kratochwill","given":"T. R.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Levin","given":"Joel R","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Psychological Methods","id":"ITEM-1","issue":"2","issued":{"date-parts":[["2010"]]},"page":"124-144","title":"Enhancing the scientific credibility of single-case intervention research: Randomization to the rescue","type":"article-journal","volume":"15"},"uris":["http://www.mendeley.com/documents/?uuid=ddfbcc90-d048-4d65-9827-fac88001c360"]},{"id":"ITEM-2","itemData":{"DOI":"10.1177/001440290507100203","ISSN":"00144029","abstract":"Single-subject research plays an important role in the development of evidence-based practice in special education. The defining features of single-subject research are presented, the contributions of single-subject research for special education are reviewed, and a specific proposal is offered for using single-subject research to document evidence-based practice. This article allows readers to determine if a specific study is a credible example of single-subject research and if a specific practice or procedure has been validated as \"evidence-based\" via single-subject research.","author":[{"dropping-particle":"","family":"Horner","given":"Robert H.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Carr","given":"Edward G.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Halle","given":"James","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Mcgee","given":"Gail","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Odom","given":"Samuel","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Wolery","given":"Mark","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Exceptional Children","id":"ITEM-2","issue":"2","issued":{"date-parts":[["2005"]]},"page":"165-179","title":"The use of single-subject research to identify evidence-based practice in special education","type":"article-journal","volume":"71"},"uris":["http://www.mendeley.com/documents/?uuid=57971ed7-7e9c-446d-b7a8-2e2d0ba25a7c"]}],"mendeley":{"formattedCitation":"(Horner et al., 2005; Kratochwill & Levin, 2010)","plainTextFormattedCitation":"(Horner et al., 2005; Kratochwill & Levin, 2010)","previouslyFormattedCitation":"(Horner et al., 2005; Kratochwill & Levin, 2010)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Horner et al., 2005; Kratochwill & Levin, 2010). In our study design, we incorporated both randomization and replication to enhance internal and external validity of the experiment. Advantages of SCEs for Classical ConditioningSCEs are well suited to research questions about within-individual processes. Although group designs are historically respected, they are typically analyzed in a way that aggregates data from all individuals to estimate an effect at the group level—an effect that may be non-existent in any of the individuals within the group ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1111/j.1467-8721.2009.01619.x","ISSN":"0963-7214","abstract":"Most research methodology in the behavioral sciences employs interindividual analyses, which provide information about the state of affairs of the population. However, as shown by classical mathematical-statistical theorems (the ergodic theorems), such analyses do not provide information for, and cannot be applied at, the level of the individual, except on rare occasions when the processes of interest meet certain stringent conditions. When psychological processes violate these conditions, the interindividual analyses that are now standardly applied have to be replaced by analysis of intraindividual variation in order to obtain valid results. Two illustrations involving analysis of intraindividual variation of personality and emotional processes are given.","author":[{"dropping-particle":"","family":"Molenaar","given":"Peter C M","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Campbell","given":"Cynthia G","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Current Directions in Psychological Science","id":"ITEM-1","issue":"2","issued":{"date-parts":[["2009","4","1"]]},"note":"doi: 10.1111/j.1467-8721.2009.01619.x","page":"112-117","publisher":"SAGE Publications Inc","title":"The new person-specific paradigm in psychology","type":"article-journal","volume":"18"},"uris":["http://www.mendeley.com/documents/?uuid=688f9077-cb4d-4bc4-b2b3-00e6024c5f5a"]}],"mendeley":{"formattedCitation":"(Molenaar & Campbell, 2009)","plainTextFormattedCitation":"(Molenaar & Campbell, 2009)","previouslyFormattedCitation":"(Molenaar & Campbell, 2009)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Molenaar & Campbell, 2009). This aggregation approach obscures the true, within-individual effect, and the between-individual variability of that effect (which, itself, is typically worthy of attention; ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1073/pnas.1711978115","abstract":"The current study quantified the degree to which group data are able to describe individual participants. We utilized intensive repeated-measures data—data that have been collected many times, across many individuals—to compare the distributions of bivariate correlations calculated within subjects vs. those calculated between subjects. Because the vast majority of social and medical science research aggregates across subjects, we aimed to assess how closely such aggregations reflect their constituent individuals. We provide evidence that conclusions drawn from aggregated data may be worryingly imprecise. Specifically, the variance in individuals is up to four times larger than in groups. These data call for a focus on idiography and open science that may substantially alter best-practice guidelines in the medical and behavioral sciences.Only for ergodic processes will inferences based on group-level data generalize to individual experience or behavior. Because human social and psychological processes typically have an individually variable and time-varying nature, they are unlikely to be ergodic. In this paper, six studies with a repeated-measure design were used for symmetric comparisons of interindividual and intraindividual variation. Our results delineate the potential scope and impact of nonergodic data in human subjects research. Analyses across six samples (with 87–94 participants and an equal number of assessments per participant) showed some degree of agreement in central tendency estimates (mean) between groups and individuals across constructs and data collection paradigms. However, the variance around the expected value was two to four times larger within individuals than within groups. This suggests that literatures in social and medical sciences may overestimate the accuracy of aggregated statistical estimates. This observation could have serious consequences for how we understand the consistency between group and individual correlations, and the generalizability of conclusions between domains. Researchers should explicitly test for equivalence of processes at the individual and group level across the social and medical sciences.","author":[{"dropping-particle":"","family":"Fisher","given":"Aaron J","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Medaglia","given":"John D","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Jeronimus","given":"Bertus F","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Proceedings of the National Academy of Sciences","id":"ITEM-1","issue":"27","issued":{"date-parts":[["2018","7","3"]]},"page":"E6106 LP  - E6115","title":"Lack of group-to-individual generalizability is a threat to human subjects research","type":"article-journal","volume":"115"},"uris":["http://www.mendeley.com/documents/?uuid=86f12e6a-3f0a-4d68-a93f-a10143d5b5e0"]}],"mendeley":{"formattedCitation":"(Fisher et al., 2018)","manualFormatting":"Fisher et al., 2018)","plainTextFormattedCitation":"(Fisher et al., 2018)","previouslyFormattedCitation":"(Fisher et al., 2018)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}Fisher et al., 2018). Of course, it is possible to consider within-individual changes in some group designs, but an SCE offers a superior approach to achieving a sufficiently powered (> 80%) examination of within-subject effects ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"author":[{"dropping-particle":"","family":"Ferron","given":"John","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Ware","given":"William","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"The Journal of Experimental Education","id":"ITEM-1","issue":"2","issued":{"date-parts":[["1995"]]},"page":"167-178","title":"Analyzing single-case data: The power of randomization tests","type":"article-journal","volume":"63"},"uris":["http://www.mendeley.com/documents/?uuid=10969372-d714-4dd9-be5d-56f2952ac89a"]},{"id":"ITEM-2","itemData":{"DOI":"10.1080/00220973.1996.9943805","ISBN":"0022-0973","ISSN":"19400683","abstract":"Monte Carlo methods were used to estimate the power of randomization tests used with single-case designs involving the random assignment of treatments to phases. The design studied involved 2 treatments and 6 phases. The power was studied for 6 standardized effect sizes (0, .2, .5, .8, 1.1, and 1.4), 4 levels of autocorrelation (1st order autocorrelation coefficients of -.3, 0, .3, and .6), and 5 different phase lengths (4, 5, 6, 7, and 8 observations). Power was estimated for each condition by simulating 10,000 experiments. The results showed an adequate level of power (> .80) when effect sizes were large (1.1 and 1.4), phase lengths exceeded 5, and autocorrelation was not negative.","author":[{"dropping-particle":"","family":"Ferron","given":"John","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Journal of Experimental Education","id":"ITEM-2","issue":"3","issued":{"date-parts":[["1996"]]},"page":"231-239","title":"The power of randomization tests for single-case phase designs","type":"article-journal","volume":"64"},"uris":["http://www.mendeley.com/documents/?uuid=a041ea39-019c-41f1-84e0-80ff61fccbc1"]}],"mendeley":{"formattedCitation":"(Ferron & Onghena, 1996; Ferron & Ware, 1995)","plainTextFormattedCitation":"(Ferron & Onghena, 1996; Ferron & Ware, 1995)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Ferron & Onghena, 1996; Ferron & Ware, 1995). Whereas traditional group-based designs generate knowledge on the population level only, SCEs generate knowledge at the level of the individual. Finally, findings from group-based designs cannot be generalized towards individuals, while SCEs can be aggregated for insights on populations.Analyzing SCEsSCEs are often difficult to analyze due to the presence of serial correlation in observed data and nonadherence to distributional assumptions ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"ISBN":"0191-5401(Print)","abstract":"Reports that in single-S, single-case, small-sample, or interrupted time-series research, a conflict exists regarding whether sampling errors of observations obtained during baseline or intervention are independent so that statistical procedures such as analysis of variance (ANOVA) and regression can be applied to the data. In the present study, observations from 101 baseline phases and 125 intervention phases were examined for autocorrelation. Data show that many single-S studies were based on data in which the autocorrelations tended to be larger than zero and were measured on samples for which the test for identifying a nonzero autocorrelation as significant had low power. Results question the recommendations made by B. E. Huitema (see record 1986-08129-001) that classical data analytic procedures can be employed for single-S studies. (PsycINFO Database Record (c) 2016 APA, all rights reserved)","author":[{"dropping-particle":"","family":"Busk","given":"Patricia L","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Marascuilo","given":"Leonard A","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Behavioral Assessment","id":"ITEM-1","issue":"3","issued":{"date-parts":[["1988"]]},"page":"229-242","publisher":"Pergamon Press, Inc.","publisher-place":"US","title":"Autocorrelation in single-subject research: A counterargument to the myth of no autocorrelation.","type":"article-journal","volume":"10"},"uris":["http://www.mendeley.com/documents/?uuid=74f7e531-03b7-42a5-ac46-16097a467507"]},{"id":"ITEM-2","itemData":{"DOI":"10.1177/0145445513510931","ISBN":"0145-4455","ISSN":"15524167","PMID":"24235178","abstract":"A wide variety of effect sizes (ESs) has been used in the single-case design literature. Several researchers have \" stress tested \" these ESs by subjecting them to various degrees of problem data (e.g., autocorrelation, slope), resulting in the conditions by which different ESs can be considered valid. However, on the back end, few researchers have considered how prevalent and severe these problems are in extant data and as a result, how concerned applied researchers should be. The current study extracted and aggregated indicators of violations of normality and independence across four domains of educational study. Significant violations were found in total and across fields, including low levels of autocorrelation and moderate levels of absolute trend. These violations affect the selection and interpretation of ESs at the individual study level and for meta-analysis. Implications and recommendations are discussed.","author":[{"dropping-particle":"","family":"Solomon","given":"Benjamin George","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Behavior Modification","id":"ITEM-2","issue":"4","issued":{"date-parts":[["2014"]]},"page":"477-496","title":"Violations of assumptions in school-based single-case data: Implications for the selection and interpretation of effect sizes","type":"article-journal","volume":"38"},"uris":["http://www.mendeley.com/documents/?uuid=11839ff2-3056-4ff3-ad43-e69b0a63d7f5"]},{"id":"ITEM-3","itemData":{"DOI":"https://doi.org/10.1006/anbe.1996.0077","ISSN":"0003-3472","abstract":"Data from behavioural studies are frequently non-normally distributed and cannot be analysed with traditional parametric statistics. Instead, behaviourists must rely on rank-transformation tests, which lose potentially valuable information present in the data. Recently, however, biologists in other disciplines have resolved similar statistical difficulties by using resampling methods. Results from Kruskal–Wallis non-parametric ANOVA and randomization tests were compared for two behavioural data sets. It was found that randomization tests were more powerful than Kruskal–Wallis, and could thus detect smaller effect sizes present in the data. In addition, the variance was calculated around theP-value at eight levels of replication ranging from 500 to 10000, to determine the optimal number of replications for the randomization test. The variance around theP-value decreased as the number of replications increased. TheP-value stabilized at 5000 replications, and thus it is recommended that at least 5000 replications be used for randomization tests on behavioural data.","author":[{"dropping-particle":"","family":"Adams","given":"Dean C","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Anthony","given":"Carl D","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Animal Behaviour","id":"ITEM-3","issue":"4","issued":{"date-parts":[["1996"]]},"page":"733-738","title":"Using randomization techniques to analyse behavioural data","type":"article-journal","volume":"51"},"uris":["http://www.mendeley.com/documents/?uuid=7af2bb5e-1012-44cf-9930-577e677fe190"]},{"id":"ITEM-4","itemData":{"DOI":"10.1037/a0029312","ISBN":"1939-1463(Electronic);1082-989X(Print)","ISSN":"1939-1463","PMID":"22845874","abstract":"This article systematically reviews the research design and methodological characteristics of single-case experimental design (SCED) research published in peer-reviewed journals between 2000 and 2010. SCEDs provide researchers with a flexible and viable alternative to group designs with large sample sizes. However, methodological challenges have precluded widespread implementation and acceptance of the SCED as a viable complementary methodology to the predominant group design. This article includes a description of the research design, measurement, and analysis domains distinctive to the SCED; a discussion of the results within the framework of contemporary standards and guidelines in the field; and a presentation of updated benchmarks for key characteristics (e.g., baseline sampling, method of analysis), and overall, it provides researchers and reviewers with a resource for conducting and evaluating SCED research. The results of the systematic review of 409 studies suggest that recently published SCED research is largely in accordance with contemporary criteria for experimental quality. Analytic method emerged as an area of discord. Comparison of the findings of this review with historical estimates of the use of statistical analysis indicates an upward trend, but visual analysis remains the most common analytic method and also garners the most support among those entities providing SCED standards. Although consensus exists along key dimensions of single-case research design, and researchers appear to be practicing within these parameters, there remains a need for further evaluation of assessment and sampling techniques and data analytic methods.","author":[{"dropping-particle":"","family":"Smith","given":"Justin D.","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Psychological Methods","id":"ITEM-4","issue":"4","issued":{"date-parts":[["2012"]]},"page":"510-550","title":"Single-case experimental designs: A systematic review of published research and current standards","type":"article-journal","volume":"17"},"uris":["http://www.mendeley.com/documents/?uuid=262394ee-ba03-418c-8487-7cc5f4ad196a"]}],"mendeley":{"formattedCitation":"(Adams & Anthony, 1996; Busk & Marascuilo, 1988; Smith, 2012; Solomon, 2014)","plainTextFormattedCitation":"(Adams & Anthony, 1996; Busk & Marascuilo, 1988; Smith, 2012; Solomon, 2014)","previouslyFormattedCitation":"(Adams & Anthony, 1996; Busk & Marascuilo, 1988; Smith, 2012; Solomon, 2014)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Adams & Anthony, 1996; Busk & Marascuilo, 1988; Smith, 2012; Solomon, 2014). Traditionally, visual analysis was the preferred method for analyzing SCE data, but researchers now recommend quantitative statistical analysis to complement visual analysis ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1177/002246699002300407","ISSN":"0022-4669","abstract":"The agreement between visual analysis and the results of the split-middle method of trend estimation was examined using a set of 24 stimulus graphs. Thirty raters indicated whether a significant change occurred across the phases of the stimulus graphs. The average visual analysis score for each graph was then compared to the results of the split-middle method of trend estimation. Using the trend line and tables based on the cumulative binomial probability distribution, a statistical statement of change across design phases was generated. The level of agreement between visual and statistical inferences was .46. The sensitivity, specificity, and predictive value of visual analysis in relation to the statistical conclusions ranged from .38 to .73. Findings indicate the need for continued investigation of the various properties of visual and statistical analysis as applied to single subject data.","author":[{"dropping-particle":"","family":"Ottenbacher","given":"Kenneth J","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"The Journal of Special Education","id":"ITEM-1","issue":"4","issued":{"date-parts":[["1990","1","1"]]},"note":"doi: 10.1177/002246699002300407","page":"436-449","publisher":"SAGE Publications Inc","title":"When is a picture worth a thousand p values? A comparison of visual and quantitative methods to analyze single subject data","type":"article-journal","volume":"23"},"uris":["http://www.mendeley.com/documents/?uuid=6ac9fab7-9fe1-4444-87d5-e0f6a30a5d50"]},{"id":"ITEM-2","itemData":{"DOI":"10.1901/jaba.1990.23-341","ISSN":"0021-8855","abstract":"Visual analysis is the dominant method of analysis for single-case time series. The literature assumes that visual analysts will be conservative judges. We show that previous research into visual analysis has not adequately examined false alarm and miss rates or the effect of serial dependence. In order to measure false alarm and miss rates while varying serial dependence, amount of random variability, and effect size, 37 students undertaking a postgraduate course in single-case design and analysis were required to assess the presence of an intervention effect in each of 27 AB charts constructed using a first-order autoregressive model. Three levels of effect size and three levels of variability, representative of values found in published charts, were combined with autocorrelation coefficients of 0, 0.3 and 0.6 in a factorial design. False alarm rates were surprisingly high (16% to 84%). Positive autocorrelation and increased random variation both significantly increased the false alarm rates and interacted in a nonlinear fashion. Miss rates were relatively low (0% to 22%) and were not significantly affected by the design parameters. Thus, visual analysts were not conservative, and serial dependence did influence judgment.","author":[{"dropping-particle":"","family":"Matyas","given":"T A","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Greenwood","given":"K M","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Journal of applied behavior analysis","id":"ITEM-2","issue":"3","issued":{"date-parts":[["1990"]]},"page":"341-351","title":"Visual analysis of single-case time series: Effects of variability, serial dependence, and magnitude of intervention effects","type":"article-journal","volume":"23"},"uris":["http://www.mendeley.com/documents/?uuid=e409d006-b37a-4457-8234-b2da63d44f77"]},{"id":"ITEM-3","itemData":{"ISBN":"2072366658","abstract":"In an effort to expand the pool of scientific evidence available for review, the What Works Clearinghouse (WWC) assembled a panel of national experts in single-case design (SCD) and analysis to draft SCD Standards. In this paper, the panel provides an overview of SCDs, specifies the types of questions that SCDs are designed to answer, and discusses the internal validity of SCDs. The panel then proposes SCD Standards to be implemented by the WWC. The Standards are bifurcated into Design and Evidence Standards (see Figure 1). The Design Standards evaluate the internal validity of the design. Reviewers assign the categories of Meets Standards, Meets Standards with Reservations and Does not Meet Standards to each study based on the Design Standards. Reviewers trained in visual analysis will then apply the Evidence Standards to studies that meet standards (with or without reservations), resulting in the categorization of each outcome variable as demonstrating Strong Evidence, Moderate Evidence, or No Evidence.","author":[{"dropping-particle":"","family":"Kratochwill","given":"T. R.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Hitchcock","given":"J","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Horner","given":"Robert H","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Levin","given":"J R","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Odom","given":"S L","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Rindskopf","given":"D M","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Shadish","given":"W R","non-dropping-particle":"","parse-names":false,"suffix":""}],"id":"ITEM-3","issued":{"date-parts":[["2010"]]},"title":"Single-case design technical documentation","type":"article"},"uris":["http://www.mendeley.com/documents/?uuid=5dcf7b6e-f904-44b1-9c41-015a9c911322"]},{"id":"ITEM-4","itemData":{"DOI":"10.1017/BrImp.2017.17","ISSN":"18395252","abstract":"Single-case experimental designs meeting evidence standards are useful for identifying empirically-supported practices. Part of the research process entails data analysis, which can be performed both visually and numerically. In the current text, we discuss several statistical techniques focusing on the descriptive quantifications that they provide on aspects such as overlap, difference in level and in slope. In both cases, the numerical results are interpreted in light of the characteristics of the data as identified via visual inspection. Two previously published data sets from patients with traumatic brain injury are re-analysed, illustrating several analytical options and the data patterns for which each of these analytical techniques is especially useful, considering their assumptions and limitations. In order to make the current review maximally informative for applied researchers, we point to free user-friendly web applications of the analytical techniques. Moreover, we offer up-to-date references to the potentially useful analytical techniques not illustrated in the article. Finally, we point to some analytical challenges and offer tentative recommendations about how to deal with them.","author":[{"dropping-particle":"","family":"Manolov","given":"Rumen","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Solanas","given":"Antonio","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Brain Impairment","id":"ITEM-4","issue":"1","issued":{"date-parts":[["2018"]]},"page":"18-32","title":"Analytical options for single-case experimental designs: Review and application to brain impairment","type":"article-journal","volume":"19"},"uris":["http://www.mendeley.com/documents/?uuid=4721ed20-453c-4fb0-a49d-2eac81d9d519"]},{"id":"ITEM-5","itemData":{"DOI":"10.1016/j.beth.2016.04.008","ISSN":"18781888","PMID":"28077224","abstract":"The current paper responds to the need to provide guidance to applied single-case researchers regarding the possibilities of data analysis. The amount of available single-case data analytical techniques has been growing during recent years and a general overview, comparing the possibilities of these techniques, is missing. Such an overview is provided that refers to techniques that yield results in terms of a raw or standardized difference and procedures related to regression analysis, as well as nonoverlap and percentage change indices. The comparison is provided in terms of the type of quantification provided, data features taken into account, conditions in which the techniques are appropriate, possibilities for meta-analysis, and evidence available on their performance. Moreover, we provide a set of recommendations for choosing appropriate analysis techniques, pointing at specific situations (aims, types of data, researchers’ resources) and the data analytical techniques that are most appropriate in these situations. The recommendations are contextualized using a variety of published single-case data sets in order to illustrate a range of realistic situations that researchers have faced and may face in their investigations.","author":[{"dropping-particle":"","family":"Manolov","given":"Rumen","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Moeyaert","given":"Mariola","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Behavior Therapy","id":"ITEM-5","issue":"1","issued":{"date-parts":[["2017"]]},"page":"97-114","publisher":"Elsevier B.V.","title":"Recommendations for choosing single-case data analytical techniques","type":"article-journal","volume":"48"},"uris":["http://www.mendeley.com/documents/?uuid=6d3fa4a6-b213-4df7-bb61-431c358a439c"]}],"mendeley":{"formattedCitation":"(Kratochwill et al., 2010; Manolov & Moeyaert, 2017; Manolov & Solanas, 2018; Matyas & Greenwood, 1990; Ottenbacher, 1990)","plainTextFormattedCitation":"(Kratochwill et al., 2010; Manolov & Moeyaert, 2017; Manolov & Solanas, 2018; Matyas & Greenwood, 1990; Ottenbacher, 1990)","previouslyFormattedCitation":"(Kratochwill et al., 2010; Manolov & Moeyaert, 2017; Manolov & Solanas, 2018; Matyas & Greenwood, 1990; Ottenbacher, 1990)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Kratochwill et al., 2010; Manolov & Moeyaert, 2017; Manolov & Solanas, 2018; Matyas & Greenwood, 1990; Ottenbacher, 1990). Specifically, for experiments involving user-reported ordinal data, such as the current experiment, nonparametric statistical methods may be best suited for analysis, as the observed data may not adhere to distributional assumptions required for popular parametric methods. Randomization tests (RTs) are nonparametric hypothesis tests recommended for analyzing SCEs ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1080/00223980.1975.9923926","ISSN":"0022-3980","author":[{"dropping-particle":"","family":"Edgington","given":"Eugene S","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Journal of Psychology","id":"ITEM-1","issue":"1","issued":{"date-parts":[["1975","5","1"]]},"note":"Last updated - 2013-02-21","page":"57","publisher":"Journal Press, etc.","publisher-place":"Provincetown, Mass., etc.","title":"Randomization tests for one-subject operant experiments","type":"article-journal","volume":"90"},"uris":["http://www.mendeley.com/documents/?uuid=b8cbd2f4-cfe3-4ff2-81ed-267a4033f315"]},{"id":"ITEM-2","itemData":{"DOI":"https://doi.org/10.1006/anbe.1996.0077","ISSN":"0003-3472","abstract":"Data from behavioural studies are frequently non-normally distributed and cannot be analysed with traditional parametric statistics. Instead, behaviourists must rely on rank-transformation tests, which lose potentially valuable information present in the data. Recently, however, biologists in other disciplines have resolved similar statistical difficulties by using resampling methods. Results from Kruskal–Wallis non-parametric ANOVA and randomization tests were compared for two behavioural data sets. It was found that randomization tests were more powerful than Kruskal–Wallis, and could thus detect smaller effect sizes present in the data. In addition, the variance was calculated around theP-value at eight levels of replication ranging from 500 to 10000, to determine the optimal number of replications for the randomization test. The variance around theP-value decreased as the number of replications increased. TheP-value stabilized at 5000 replications, and thus it is recommended that at least 5000 replications be used for randomization tests on behavioural data.","author":[{"dropping-particle":"","family":"Adams","given":"Dean C","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Anthony","given":"Carl D","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Animal Behaviour","id":"ITEM-2","issue":"4","issued":{"date-parts":[["1996"]]},"page":"733-738","title":"Using randomization techniques to analyse behavioural data","type":"article-journal","volume":"51"},"uris":["http://www.mendeley.com/documents/?uuid=7af2bb5e-1012-44cf-9930-577e677fe190"]},{"id":"ITEM-3","itemData":{"DOI":"10.1016/j.jcbs.2013.10.002","ISBN":"22121447","ISSN":"2212-1447","abstract":"A single-case experimental design is a research design that can be used to evaluate the effect of an intervention for a single entity. There are two important schedules to include randomization into the design of single-case experiments: phase designs and alternation designs. We present these two schedules and provide a detailed example for each schedule. For both examples, we illustrate the use of a free software package that assists researchers in designing and analyzing single-case experiments using randomization tests. Furthermore, we discuss several additions (simultaneous and sequential replication designs; meta-analysis of single-case experimental studies) and alternatives (statistical and visual analysis methods).","author":[{"dropping-particle":"","family":"Heyvaert","given":"Mieke","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Journal of Contextual Behavioral Science","id":"ITEM-3","issue":"1","issued":{"date-parts":[["2014"]]},"page":"51-64","title":"Randomization tests for single-case experiments: State of the art, state of the science, and state of the application","type":"article-journal","volume":"3"},"uris":["http://www.mendeley.com/documents/?uuid=198ba9d4-5192-465e-95ce-823dacfeb34c"]}],"mendeley":{"formattedCitation":"(Adams & Anthony, 1996; Edgington, 1975; Heyvaert & Onghena, 2014b)","plainTextFormattedCitation":"(Adams & Anthony, 1996; Edgington, 1975; Heyvaert & Onghena, 2014b)","previouslyFormattedCitation":"(Adams & Anthony, 1996; Edgington, 1975; Heyvaert & Onghena, 2014b)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Adams & Anthony, 1996; Edgington, 1975; Heyvaert & Onghena, 2014b). RTs derive their validity from the random assignment of treatment conditions to experimental units, which in the case of SCEs, are measurement occasions ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"author":[{"dropping-particle":"","family":"Edgington","given":"Eugene S","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"edition":"4","id":"ITEM-1","issued":{"date-parts":[["2007"]]},"publisher":"Chapman & Hall/CRC","publisher-place":"Boca Raton, FL","title":"Randomization tests","type":"book"},"uris":["http://www.mendeley.com/documents/?uuid=c270a3d6-ab9f-433c-8337-2d2d654ae540"]}],"mendeley":{"formattedCitation":"(Edgington & Onghena, 2007)","plainTextFormattedCitation":"(Edgington & Onghena, 2007)","previouslyFormattedCitation":"(Edgington & Onghena, 2007)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Edgington & Onghena, 2007). RTs do not require any distributional assumptions for the observed data. Additionally, RTs are immensely flexible, and can be adapted for any SCE design, randomization scheme, and effect size measure as the test statistic ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.3758/s13428-019-01266-6","ISSN":"1554-3528","abstract":"Multilevel models (MLMs) have been proposed in single-case research, to synthesize data from a group of cases in a multiple-baseline design (MBD). A limitation of this approach is that MLMs require several statistical assumptions that are often violated in single-case research. In this article we propose a solution to this limitation by presenting a randomization test (RT) wrapper for MLMs that offers a nonparametric way to evaluate treatment effects, without making distributional assumptions or an assumption of random sampling. We present the rationale underlying the proposed technique and validate its performance (with respect to Type I error rate and power) as compared to parametric statistical inference in MLMs, in the context of evaluating the average treatment effect across cases in an MBD. We performed a simulation study that manipulated the numbers of cases and of observations per case in a dataset, the data variability between cases, the distributional characteristics of the data, the level of autocorrelation, and the size of the treatment effect in the data. The results showed that the power of the RT wrapper is superior to the power of parametric tests based on F distributions for MBDs with fewer than five cases, and that the Type I error rate of the RT wrapper is controlled for bimodal data, whereas this is not the case for traditional MLMs.","author":[{"dropping-particle":"","family":"Michiels","given":"Bart","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Tanious","given":"René","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"De","given":"Tamal Kumar","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Behavior Research Methods","id":"ITEM-1","issue":"2","issued":{"date-parts":[["2020"]]},"page":"654-666","title":"A randomization test wrapper for synthesizing single-case experiments using multilevel models: A Monte Carlo simulation study","type":"article-journal","volume":"52"},"uris":["http://www.mendeley.com/documents/?uuid=68735d7b-ea0d-438f-af99-3a06a1ddde0b"]},{"id":"ITEM-2","itemData":{"DOI":"10.1080/09602011.2013.818564","ISBN":"09602011 (ISSN)","ISSN":"14640694","PMID":"23865938","abstract":"Single-case experiments can be used to evaluate the effect of an intervention or treatment for a single entity. The internal validity and statistical conclusion validity of single-case experiments can be improved by incorporating randomisation in their design. In this article, we explain how to design randomised single-case phase and alternation studies as well as randomised simultaneous and sequential replication studies, and how to conduct randomisation tests for these designs. Advantages and limitations of randomisation tests are discussed. In order to not only determine the (non)randomness of an intervention effect, but also the magnitude of this effect, we propose to use an effect size index as a test statistic for the randomisation test. We illustrate this combination for the design and analysis of an ABAB phase study, using a free software package.","author":[{"dropping-particle":"","family":"Heyvaert","given":"Mieke","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Neuropsychological Rehabilitation","id":"ITEM-2","issue":"3-4","issued":{"date-parts":[["2014"]]},"page":"507-527","title":"Analysis of single-case data: Randomisation tests for measures of effect size","type":"article-journal","volume":"24"},"uris":["http://www.mendeley.com/documents/?uuid=2b7622b9-97a6-4dc8-8789-3f3716c9bcc5"]},{"id":"ITEM-3","itemData":{"DOI":"10.1016/j.jcbs.2013.10.002","ISBN":"22121447","ISSN":"2212-1447","abstract":"A single-case experimental design is a research design that can be used to evaluate the effect of an intervention for a single entity. There are two important schedules to include randomization into the design of single-case experiments: phase designs and alternation designs. We present these two schedules and provide a detailed example for each schedule. For both examples, we illustrate the use of a free software package that assists researchers in designing and analyzing single-case experiments using randomization tests. Furthermore, we discuss several additions (simultaneous and sequential replication designs; meta-analysis of single-case experimental studies) and alternatives (statistical and visual analysis methods).","author":[{"dropping-particle":"","family":"Heyvaert","given":"Mieke","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Journal of Contextual Behavioral Science","id":"ITEM-3","issue":"1","issued":{"date-parts":[["2014"]]},"page":"51-64","title":"Randomization tests for single-case experiments: State of the art, state of the science, and state of the application","type":"article-journal","volume":"3"},"uris":["http://www.mendeley.com/documents/?uuid=198ba9d4-5192-465e-95ce-823dacfeb34c"]}],"mendeley":{"formattedCitation":"(Heyvaert & Onghena, 2014a, 2014b; Michiels et al., 2020)","plainTextFormattedCitation":"(Heyvaert & Onghena, 2014a, 2014b; Michiels et al., 2020)","previouslyFormattedCitation":"(Heyvaert & Onghena, 2014a, 2014b; Michiels et al., 2020)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Heyvaert & Onghena, 2014a, 2014b; Michiels et al., 2020). In our study design, we implemented a customized RT using a mean difference effect size measure as the test statistic. Statistical Power of SCE RTs Power analysis is an essential part of statistical hypothesis testing, particularly for determining sample size ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.4324/9780203771587","abstract":"Statistical Power Analysis is a nontechnical guide to power analysis in research planning that provides users of applied statistics with the tools they need for more effective analysis. The Second Edition includes:\\n* a chapter covering power analysis in set correlation and multivariate methods;\\n* a chapter considering effect size, psychometric reliability, and the efficacy of \"qualifying\" dependent variables and;\\n* expanded power and sample size tables for multiple regression/correlation.","author":[{"dropping-particle":"","family":"Cohen","given":"Jacob","non-dropping-particle":"","parse-names":false,"suffix":""}],"edition":"2","id":"ITEM-1","issued":{"date-parts":[["1988"]]},"publisher":"Routledge","publisher-place":"New York, NY","title":"Statistical power analysis for the behavioral sciences","type":"book"},"uris":["http://www.mendeley.com/documents/?uuid=ec6bbbdd-e483-3a39-b0e7-729c00cd3e50"]}],"mendeley":{"formattedCitation":"(Cohen, 1988)","plainTextFormattedCitation":"(Cohen, 1988)","previouslyFormattedCitation":"(Cohen, 1988)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Cohen, 1988). Several guidelines recommend a power analysis or at least a methodical description of how sample size was determined ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1136/bmj.h1738","ISSN":"17561833","author":[{"dropping-particle":"","family":"Vohra","given":"Sunita","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Shamseer","given":"Larissa","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Sampson","given":"Margaret","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Bukutu","given":"Cecilia","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Schmid","given":"Christopher H.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Tate","given":"Robyn","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Nikles","given":"Jane","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Zucker","given":"Deborah R.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Kravitz","given":"Richard","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Guyatt","given":"Gordon","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Altman","given":"Douglas G.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Moher","given":"David","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"BMJ (Clinical research ed.)","id":"ITEM-1","issued":{"date-parts":[["2015"]]},"page":"h1738","title":"CONSORT extension for reporting N-of-1 trials (CENT) 2015 statement","type":"article-journal","volume":"350"},"uris":["http://www.mendeley.com/documents/?uuid=3fde21e4-f6b5-41d7-ab5a-e6c0372913b8"]},{"id":"ITEM-2","itemData":{"DOI":"10.1037/0003-066X.54.8.594","ISBN":"0898620007","ISSN":"0003-066X","PMID":"18793039","abstract":"In the light of continuing debate over the applications of significance testing in psychology journals and following the publication of J. Cohen's (1994) article, the Board of Scientific Affairs (BSA) of the American Psychological Association (APA) convened a committee called the Task Force on Statistical Interference (TFSI) whose charge was \"to elucidate some of the controversial issues surrounding applications of statistics including significance testing and its alternatives; alternative underlying models and data transformation; and newer methods made possible by powerful computers\" (BSA, personal communication, February 28, 1996). After extensive discussion, the BSA recommended that publishing an article in American Psychologist, as a way to initiate discussion in the field about changes in current practices of data analysis and reporting may be appropriate. This report follows that request. Following each guideline are comments, explanations, or elaborations assembled by L. Wilkinson for the task force and under its review. The report is concerned with the use of statistical methods only and is not meant as an assessment of research methods in general. The title and format of the report are adapted from an article by J. C. Bailar and F. Mosteller (1988). (PsycINFO Database Record (c) 2012 APA, all rights reserved)","author":[{"dropping-particle":"","family":"Willkinson","given":"Leland","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"American Psychologist","id":"ITEM-2","issue":"8","issued":{"date-parts":[["1999"]]},"page":"594-604","title":"Statistical methods in psychology journals: Guidelines and explanations","type":"article-journal","volume":"54"},"uris":["http://www.mendeley.com/documents/?uuid=8931ca13-a58c-471d-934c-53e9ce052a48"]}],"mendeley":{"formattedCitation":"(Vohra et al., 2015; Willkinson, 1999)","plainTextFormattedCitation":"(Vohra et al., 2015; Willkinson, 1999)","previouslyFormattedCitation":"(Vohra et al., 2015; Willkinson, 1999)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Vohra et al., 2015; Willkinson, 1999). In the context of SCEs, power analysis can be used to determine the number of measurements necessary, and for studies with replication, the number of participants.For RTs, the randomization distribution is calculated empirically, and hence statistical power can only be estimated using computer-intensive simulations ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"ISSN":"01915401","abstract":"Randomization tests have been developed for several single-case experimental designs. It is argued, however, that the randomization tests developed by Levin, Marascuilo, and Hubert 1978 for the ABAB design and by Marascuilo and Busk 1988 for replicated ABAB designs across subjects are inappropriate. An alternative randomization procedure for the ABAB design is presented, and the appropriate corresponding randomization test is derived. It is shown how this alternative procedure has to be adapted to allow for statistical analyses of extended ABAB, parametric-variation, drug-evaluation, interaction, replication, and multiple-baseline designs. Finally, some limitations of the use of randomization tests for single-case designs are discussed, with particular reference to changing-criterion designs. © 1992.","author":[{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Behavioral Assessment","id":"ITEM-1","issue":"2","issued":{"date-parts":[["1992"]]},"page":"153-171","title":"Randomization tests for extensions and variations of ABAB single-case experimental designs: A rejoinder","type":"article-journal","volume":"14"},"uris":["http://www.mendeley.com/documents/?uuid=8fd3da70-0ba9-4190-8c92-8945f47e53bf"]},{"id":"ITEM-2","itemData":{"author":[{"dropping-particle":"","family":"Ferron","given":"John","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Ware","given":"William","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"The Journal of Experimental Education","id":"ITEM-2","issue":"2","issued":{"date-parts":[["1995"]]},"page":"167-178","title":"Analyzing single-case data: The power of randomization tests","type":"article-journal","volume":"63"},"uris":["http://www.mendeley.com/documents/?uuid=10969372-d714-4dd9-be5d-56f2952ac89a"]}],"mendeley":{"formattedCitation":"(Ferron & Ware, 1995; Onghena, 1992)","plainTextFormattedCitation":"(Ferron & Ware, 1995; Onghena, 1992)","previouslyFormattedCitation":"(Ferron & Ware, 1995; Onghena, 1992)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Ferron & Ware, 1995; Onghena, 1992). Several studies have estimated the power of SCE RTs for various design conditions ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1080/00220973.1996.9943805","ISBN":"0022-0973","ISSN":"19400683","abstract":"Monte Carlo methods were used to estimate the power of randomization tests used with single-case designs involving the random assignment of treatments to phases. The design studied involved 2 treatments and 6 phases. The power was studied for 6 standardized effect sizes (0, .2, .5, .8, 1.1, and 1.4), 4 levels of autocorrelation (1st order autocorrelation coefficients of -.3, 0, .3, and .6), and 5 different phase lengths (4, 5, 6, 7, and 8 observations). Power was estimated for each condition by simulating 10,000 experiments. The results showed an adequate level of power (> .80) when effect sizes were large (1.1 and 1.4), phase lengths exceeded 5, and autocorrelation was not negative.","author":[{"dropping-particle":"","family":"Ferron","given":"John","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Journal of Experimental Education","id":"ITEM-1","issue":"3","issued":{"date-parts":[["1996"]]},"page":"231-239","title":"The power of randomization tests for single-case phase designs","type":"article-journal","volume":"64"},"uris":["http://www.mendeley.com/documents/?uuid=a041ea39-019c-41f1-84e0-80ff61fccbc1"]},{"id":"ITEM-2","itemData":{"author":[{"dropping-particle":"","family":"Ferron","given":"John","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Ware","given":"William","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"The Journal of Experimental Education","id":"ITEM-2","issue":"2","issued":{"date-parts":[["1995"]]},"page":"167-178","title":"Analyzing single-case data: The power of randomization tests","type":"article-journal","volume":"63"},"uris":["http://www.mendeley.com/documents/?uuid=10969372-d714-4dd9-be5d-56f2952ac89a"]},{"id":"ITEM-3","itemData":{"DOI":"10.3758/s13428-017-0885-7","ISSN":"15543528","PMID":"28389851","abstract":"Behav Res, doi:10.3758/s13428-017-0885-7","author":[{"dropping-particle":"","family":"Michiels","given":"Bart","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Heyvaert","given":"Mieke","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Behavior Research Methods","id":"ITEM-3","issue":"2","issued":{"date-parts":[["2018"]]},"page":"557-575","publisher":"Behavior Research Methods","title":"The conditional power of randomization tests for single-case effect sizes in designs with randomized treatment order: A Monte Carlo simulation study","type":"article-journal","volume":"50"},"uris":["http://www.mendeley.com/documents/?uuid=cea25ef0-03bd-4861-b740-fc9abe136eef"]},{"id":"ITEM-4","itemData":{"DOI":"10.1371/journal.pone.0228355","ISBN":"1111111111","ISSN":"19326203","PMID":"32027683","abstract":"A randomization test can be used to statistically test hypotheses in multiple baseline designs to complement the commonly used visual inspection analysis. A crossed factor simulation study was performed to investigate the power of a randomization test in an multiple baseline design. The results show that the degree of autocorrelation of the observations, the number of participants, the effect size, the overlap of possible start moments of the intervention between participants, the ratio of the number of measurements in the baseline- and intervention phase, a gradually emerging effect, and the number of measurements had strong main effects on the power. The two-way interactions between number of participants and effect size, and between the number of measurements and the number of start moments of the intervention also had a large effect. An online tool was developed to calculate the power of a multiple baseline design given several design characteristics.","author":[{"dropping-particle":"","family":"Bouwmeester","given":"Samantha","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Jongerling","given":"Joran","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"PLoS ONE","id":"ITEM-4","issue":"2","issued":{"date-parts":[["2020"]]},"page":"1-21","title":"Power of a randomization test in a single case multiple baseline AB design","type":"article-journal","volume":"15"},"uris":["http://www.mendeley.com/documents/?uuid=aaf017b0-4754-487e-b98c-ef2839b5af9e"]},{"id":"ITEM-5","itemData":{"DOI":"10.1080/00220970209599504","ISBN":"00220973","ISSN":"19400683","abstract":"Statistical power was estimated for 3 randomization tests used with multiple-baseline designs. In 1 test, participants were randomly assigned to baseline conditions; in the 2nd, intervention points were randomly assigned; and in the 3rd, the authors used both forms of random assignment. Power was studied for several series lengths (N = 10, 20, 30), several effect sizes (d = 0, 0.5, 1.0, 1.5, 2.0), and several levels of autocorrelation among the errors (Ï â‚ = 0, .1, .2, .3, .4, and .5). Power was found to be similar among the 3 tests. Power was low for effect sizes of 0.5 and 1.0 but was often adequate (&gt .80) for effect sizes of 1.5 and 2.0.","author":[{"dropping-particle":"","family":"Ferron","given":"John","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Sentovich","given":"Chris","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Journal of Experimental Education","id":"ITEM-5","issue":"2","issued":{"date-parts":[["2002"]]},"page":"165-178","title":"Statistical power of randomization tests used with multiple-baseline designs","type":"article-journal","volume":"70"},"uris":["http://www.mendeley.com/documents/?uuid=018afbef-dc5b-44ed-a9d6-605525ea8e5a"]},{"id":"ITEM-6","itemData":{"DOI":"10.3758/s13428-019-01320-3","ISSN":"15543528","PMID":"31898296","abstract":"Single-case experiments have become increasingly popular in psychological and educational research. However, the analysis of single-case data is often complicated by the frequent occurrence of missing or incomplete data. If missingness or incompleteness cannot be avoided, it becomes important to know which strategies are optimal, because the presence of missing data or inadequate data handling strategies may lead to experiments no longer “meeting standards” set by, for example, the What Works Clearinghouse. For the examination and comparison of strategies to handle missing data, we simulated complete datasets for ABAB phase designs, randomized block designs, and multiple-baseline designs. We introduced different levels of missingness in the simulated datasets by randomly deleting 10%, 30%, and 50% of the data. We evaluated the type I error rate and statistical power of a randomization test for the null hypothesis that there was no treatment effect under these different levels of missingness, using different strategies for handling missing data: (1) randomizing a missing-data marker and calculating all reference statistics only for the available data points, (2) estimating the missing data points by single imputation using the state space representation of a time series model, and (3) multiple imputation based on regressing the available data points on preceding and succeeding data points. The results are conclusive for the conditions simulated: The randomized-marker method outperforms the other two methods in terms of statistical power in a randomization test, while keeping the type I error rate under control.","author":[{"dropping-particle":"","family":"De","given":"Tamal Kumar","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Michiels","given":"Bart","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Tanious","given":"René","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Behavior Research Methods","id":"ITEM-6","issue":"3","issued":{"date-parts":[["2020"]]},"page":"1355-1370","title":"Handling missing data in randomization tests for single-case experiments: A simulation study","type":"article-journal","volume":"52"},"uris":["http://www.mendeley.com/documents/?uuid=3f81dd4a-3b90-4d7c-8466-29e57b7ea490"]}],"mendeley":{"formattedCitation":"(Bouwmeester & Jongerling, 2020; De, Michiels, Tanious, et al., 2020; Ferron & Onghena, 1996; Ferron & Sentovich, 2002; Ferron & Ware, 1995; Michiels et al., 2018)","plainTextFormattedCitation":"(Bouwmeester & Jongerling, 2020; De, Michiels, Tanious, et al., 2020; Ferron & Onghena, 1996; Ferron & Sentovich, 2002; Ferron & Ware, 1995; Michiels et al., 2018)","previouslyFormattedCitation":"(Bouwmeester & Jongerling, 2020; De, Michiels, Tanious, et al., 2020; Ferron & Onghena, 1996; Ferron & Sentovich, 2002; Ferron & Ware, 1995; Michiels et al., 2018)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Bouwmeester & Jongerling, 2020; De, Michiels, Tanious, et al., 2020; Ferron & Onghena, 1996; Ferron & Sentovich, 2002; Ferron & Ware, 1995; Michiels et al., 2018). Although the results from these studies can be used as a reference, they are true only for the design parameters and simulated data distributions considered. Since we acquired unusual ordinal observed data, power ideally needed to be estimated using simulated data of the same type as this study would generate.MethodsExperimental SetupIn this experiment, participants receive two different types of stimuli: a vibrotactile stimulation as the conditioned stimulus (CS) and an electrocutaneous stimulation as the unconditioned stimulus (US). At first, one neutral stimulus (a vibrotactile stimulus, denoted as CS+) is paired with a painful stimulus (a high-intensity electrocutaneous stimulus, denoted as UShigh), whereas a different neutral stimulus (a vibrotactile stimulus, denoted as CS−, applied to a different location) is paired with a non-painful stimulus (a low-intensity electrocutaneous stimulus, denoted as USlow). This procedure is expected to form an association between the CS+ and painfulness, in contrast to the CS− and non-painfulness. Later, each CS is paired with a “test stimulus” (denoted as UStest), an electrocutaneous stimulus of an intensity calibrated such that there is a 50% chance that the participant judges it to be painful or non-painful at baseline (i.e., before the pairing). Participants are then requested to judge each trial on a scale that distinguishes painful from non-painful events ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1016/j.jpain.2018.10.006","ISSN":"15288447","PMID":"30391525","abstract":"In experiments on pain, participants are frequently exposed to nonpainful and painful stimuli; however, the conventional pain-rating scales lack a nonpainful range and a clear point of transition from nonpainful to painful events. The Sensation and Pain Rating Scale (SPARS) assesses the full stimulus intensity range, extending from no sensation (rating: –50) to worst pain imaginable (rating: +50), and it explicitly identifies pain threshold (rating: 0). Here, we tested the SPARS in 2 experiments by using laser heat stimuli to establish its stimulus–response characteristics (Experiment 1, N = 19, 13 stimulus intensities applied 26 times each across a 1–4 J range), and compared it to 0 to 100 scales that assess nonpainful (0: no sensation, 100: pain) and painful (0: no pain, 100: worst pain imaginable) events (Experiment 2, N = 7, 9 stimulus intensities applied 36 times each across a 1.5–4.5 J range). Despite high inter- and intraindividual variations, we found a reasonably consistent curvilinear stimulus–response relationship (the curve flattens around pain threshold), with stable response characteristics across the range of the scale. The SPARS ratings transformed to a 0 to 100 range tended to be lower than the 0 to 100 pain rating scale in the noxious stimulus intensity range and greater than the 0 to 100 nonpainful sensation scale in the non-noxious stimulus range, likely reflecting differences in scale dimensionality. The SPARS overcomes limitations in scale range inherent to conventional pain rating scales. As such, it is well suited to experimental studies that must quantify a wider range of perceptual intensity or distinguish between painful and nonpainful events. Perspective: This article presents the stimulus–response characteristics of a new scale designed to allow participants to rate a range of nonpainful and painful stimuli. The scale could be useful for research that involves exposing participants to a range of stimulation intensities or requires a clear distinction between nonpainful and painful events.","author":[{"dropping-particle":"","family":"Madden","given":"Victoria J.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Kamerman","given":"Peter R.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Bellan","given":"Valeria","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Catley","given":"Mark J.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Russek","given":"Leslie N.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Camfferman","given":"Danny","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Moseley","given":"G. Lorimer","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Journal of Pain","id":"ITEM-1","issue":"4","issued":{"date-parts":[["2019"]]},"page":"472.e1-472.e12","publisher":"Elsevier Inc.","title":"Was that painful or nonpainful? The Sensation and Pain Rating Scale performs well in the experimental context","type":"article-journal","volume":"20"},"uris":["http://www.mendeley.com/documents/?uuid=158cf65d-2600-4940-8585-4da3f96fb859"]}],"mendeley":{"formattedCitation":"(Madden et al., 2019)","plainTextFormattedCitation":"(Madden et al., 2019)","previouslyFormattedCitation":"(Madden et al., 2019)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Madden et al., 2019). The trials of interest are the CS/UStest pairs, as the primary hypothesis is that, due to the pairings learned early in the experiment, the participant will come to judge the UStest stimuli to be painful more often when they are paired with the CS+ (previously paired with a painful stimulus) than when they are paired with the CS− (previously paired with a non-painful stimulus).Laboratory SetupThe participants receive two types of stimuli at the same time, replicating the procedure in Traxler et al. ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.7717/peerj.6486","ISSN":"21678359","abstract":"Background: Classical conditioning has frequently been shown to be capable of evoking fear of pain and avoidance behavior in the context of chronic pain. However, whether pain itself can be conditioned has rarely been investigated and remains a matter of debate. Therefore, the present study investigated whether pain threshold ratings can be modified by the presence of conditioned non-nociceptive sensory stimuli in healthy participant. Methods: In 51 healthy volunteers, pain threshold to electrocutaneous stimuli was determined prior to participation in a simultaneous conditioning paradigm. Participants underwent an acquisition phase in which one non-painful vibrotactile stimulus (CS+) was repeatedly paired with a painful electrocutaneous stimulus, whereas a second vibrotactile stimulus of the same quality and intensity (CS-) was paired with a non-painful electrocutaneous stimulus. Stimulation was provided on the lower back with close proximity between the conditioned stimulus and the unconditioned stimulus. In the test phase, electrocutaneous stimuli at the individually-set threshold intensity were simultaneously delivered together with either a CS+ or CS-. Pain intensity ratings were obtained after each trial; expectancy ratings were obtained after each block. The primary outcome was the percentage of test stimuli that were rated as painful. Results: Test stimuli were more likely to be rated as painful when they were paired with the CS+ than when they were paired with the CS-. This effect was not influenced by contingency awareness, nor by expectancies or mood states. Discussion: The findings support the notion that the judgement of an event being painful or non-painful can be influenced by classical conditioning and corroborate the possible role of associative learning in the development and maintenance of chronic pain.","author":[{"dropping-particle":"","family":"Traxler","given":"Juliane","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Madden","given":"Victoria J.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Moseley","given":"G. Lorimer","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Vlaeyen","given":"Johan W.S.","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"PeerJ","id":"ITEM-1","issue":"3","issued":{"date-parts":[["2019"]]},"page":"1-20","title":"Modulating pain thresholds through classical conditioning","type":"article-journal","volume":"2019"},"suppress-author":1,"uris":["http://www.mendeley.com/documents/?uuid=c5bbffe6-5041-42cb-a91c-332b22183efe"]}],"mendeley":{"formattedCitation":"(2019)","plainTextFormattedCitation":"(2019)","previouslyFormattedCitation":"(2019)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(2019). Stimulus onset and timing are controlled using Affect 4.0 ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1027/1618-3169/a000005","ISSN":"16183169","PMID":"20178962","abstract":"We describe Affect 4.0, a user-friendly software package for implementing psychological and psychophysiological experiments. Affect 4.0 can be used to present visual, acoustic, and/or tactile stimuli in highly complex (i.e., semirandomized and response-contingent) sequences. Affect 4.0 is capable of registering response latencies and analog behavioral input with millisecond accuracy. Affect 4.0 is available free of charge. © 2009 Hogrefe Publishing.","author":[{"dropping-particle":"","family":"Spruyt","given":"Adriaan","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Clarysse","given":"Jeroen","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Vansteenwegen","given":"Debora","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Baeyens","given":"Frank","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Hermans","given":"Dirk","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Experimental Psychology","id":"ITEM-1","issue":"1","issued":{"date-parts":[["2009"]]},"page":"36-45","title":"Affect 4.0: A free software package for implementing psychological and psychophysiological experiments","type":"article-journal","volume":"57"},"uris":["http://www.mendeley.com/documents/?uuid=bc9199fe-6a06-41a2-9d2a-41acde6c11a3"]}],"mendeley":{"formattedCitation":"(Spruyt et al., 2009)","plainTextFormattedCitation":"(Spruyt et al., 2009)","previouslyFormattedCitation":"(Spruyt et al., 2009)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Spruyt et al., 2009). A vibrotactile stimulus is delivered to the skin using tactors manufactured by Dancer Design taped to the participant’s skin ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"author":[{"dropping-particle":"","family":"Dancer Design","given":"","non-dropping-particle":"","parse-names":false,"suffix":""}],"id":"ITEM-1","issued":{"date-parts":[["0"]]},"publisher-place":"St. Helens, UK","title":"Tactor","type":"article"},"uris":["http://www.mendeley.com/documents/?uuid=8dd14ed3-5ae5-4bcf-9fe2-6534214dc83f"]}],"mendeley":{"formattedCitation":"(Dancer Design, n.d.)","plainTextFormattedCitation":"(Dancer Design, n.d.)","previouslyFormattedCitation":"(Dancer Design, n.d.)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Dancer Design, n.d.). This stimulus is of fixed duration and a clearly perceptible intensity. Three tactors are used in the arrangement as the source of a CS (see Figure 1). The SIDE tactor is allocated to CSneutral, whereas the ABOVE and BELOW tactors are assigned to CS+ and CS− in a counterbalanced way across participants.Figure 1Arrangement of Tactors and Electrodes on the Back (Adapted From Traxler et al. ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.7717/peerj.6486","ISSN":"21678359","abstract":"Background: Classical conditioning has frequently been shown to be capable of evoking fear of pain and avoidance behavior in the context of chronic pain. However, whether pain itself can be conditioned has rarely been investigated and remains a matter of debate. Therefore, the present study investigated whether pain threshold ratings can be modified by the presence of conditioned non-nociceptive sensory stimuli in healthy participant. Methods: In 51 healthy volunteers, pain threshold to electrocutaneous stimuli was determined prior to participation in a simultaneous conditioning paradigm. Participants underwent an acquisition phase in which one non-painful vibrotactile stimulus (CS+) was repeatedly paired with a painful electrocutaneous stimulus, whereas a second vibrotactile stimulus of the same quality and intensity (CS-) was paired with a non-painful electrocutaneous stimulus. Stimulation was provided on the lower back with close proximity between the conditioned stimulus and the unconditioned stimulus. In the test phase, electrocutaneous stimuli at the individually-set threshold intensity were simultaneously delivered together with either a CS+ or CS-. Pain intensity ratings were obtained after each trial; expectancy ratings were obtained after each block. The primary outcome was the percentage of test stimuli that were rated as painful. Results: Test stimuli were more likely to be rated as painful when they were paired with the CS+ than when they were paired with the CS-. This effect was not influenced by contingency awareness, nor by expectancies or mood states. Discussion: The findings support the notion that the judgement of an event being painful or non-painful can be influenced by classical conditioning and corroborate the possible role of associative learning in the development and maintenance of chronic pain.","author":[{"dropping-particle":"","family":"Traxler","given":"Juliane","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Madden","given":"Victoria J.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Moseley","given":"G. Lorimer","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Vlaeyen","given":"Johan W.S.","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"PeerJ","id":"ITEM-1","issue":"3","issued":{"date-parts":[["2019"]]},"page":"1-20","title":"Modulating pain thresholds through classical conditioning","type":"article-journal","volume":"2019"},"suppress-author":1,"uris":["http://www.mendeley.com/documents/?uuid=c5bbffe6-5041-42cb-a91c-332b22183efe"]}],"mendeley":{"formattedCitation":"(2019)","plainTextFormattedCitation":"(2019)","previouslyFormattedCitation":"(2019)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(2019)).[INSERT FIGURE 1 HERE]An electrocutaneous stimulation is delivered by passing a current across two surface electrodes located at the midpoint between the tactors to serve as the US (Figure 1). The current is delivered using a DS7A constant current stimulator ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"author":[{"dropping-particle":"","family":"Digitimer Limited","given":"","non-dropping-particle":"","parse-names":false,"suffix":""}],"id":"ITEM-1","issued":{"date-parts":[["0"]]},"publisher-place":"Hertfordshire, UK","title":"DS7A High Voltage Constant Current Stimulator","type":"article"},"uris":["http://www.mendeley.com/documents/?uuid=9b966096-5fdc-481d-970b-1d3b22972fdb"]}],"mendeley":{"formattedCitation":"(Digitimer Limited, n.d.)","plainTextFormattedCitation":"(Digitimer Limited, n.d.)","previouslyFormattedCitation":"(Digitimer Limited, n.d.)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Digitimer Limited, n.d.). The stimulation intensity is calibrated individually. The number of pulses delivered on each stimulation occasion is varied to provide a UShigh that is usually painful, a USlow that is usually non-painful, and a UStest that is calibrated to lie close to the pain threshold, the boundary between non-painful and painful.Tactor and Electrode PreparationOn arrival, participants are seated straddling a chair in front of a desk with a computer monitor, mouse, and keyboard. Participants are asked to bend backwards to identify the point at which the greatest bend is seen. A point in the upper lumbar region is marked on the back, 2cm to the left of the spine, where the electrodes are placed such that the mark lies exactly between them. Three other points—4cm above, below, and to the left side of the electrodes—are marked, and the tactors are taped in place such that the closest border of each tactor lies at a tactor mark (Figure 1). Calibration is performed by the procedure described in Traxler et al. ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.7717/peerj.6486","ISSN":"21678359","abstract":"Background: Classical conditioning has frequently been shown to be capable of evoking fear of pain and avoidance behavior in the context of chronic pain. However, whether pain itself can be conditioned has rarely been investigated and remains a matter of debate. Therefore, the present study investigated whether pain threshold ratings can be modified by the presence of conditioned non-nociceptive sensory stimuli in healthy participant. Methods: In 51 healthy volunteers, pain threshold to electrocutaneous stimuli was determined prior to participation in a simultaneous conditioning paradigm. Participants underwent an acquisition phase in which one non-painful vibrotactile stimulus (CS+) was repeatedly paired with a painful electrocutaneous stimulus, whereas a second vibrotactile stimulus of the same quality and intensity (CS-) was paired with a non-painful electrocutaneous stimulus. Stimulation was provided on the lower back with close proximity between the conditioned stimulus and the unconditioned stimulus. In the test phase, electrocutaneous stimuli at the individually-set threshold intensity were simultaneously delivered together with either a CS+ or CS-. Pain intensity ratings were obtained after each trial; expectancy ratings were obtained after each block. The primary outcome was the percentage of test stimuli that were rated as painful. Results: Test stimuli were more likely to be rated as painful when they were paired with the CS+ than when they were paired with the CS-. This effect was not influenced by contingency awareness, nor by expectancies or mood states. Discussion: The findings support the notion that the judgement of an event being painful or non-painful can be influenced by classical conditioning and corroborate the possible role of associative learning in the development and maintenance of chronic pain.","author":[{"dropping-particle":"","family":"Traxler","given":"Juliane","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Madden","given":"Victoria J.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Moseley","given":"G. Lorimer","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Vlaeyen","given":"Johan W.S.","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"PeerJ","id":"ITEM-1","issue":"3","issued":{"date-parts":[["2019"]]},"page":"1-20","title":"Modulating pain thresholds through classical conditioning","type":"article-journal","volume":"2019"},"suppress-author":1,"uris":["http://www.mendeley.com/documents/?uuid=c5bbffe6-5041-42cb-a91c-332b22183efe"]}],"mendeley":{"formattedCitation":"(2019)","plainTextFormattedCitation":"(2019)","previouslyFormattedCitation":"(2019)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(2019), with the CSneutral paired with each electrocutaneous stimulus. The CSneutral is used to provide vibratory stimulation consistent with the CS+/CS− stimuli that are later presented in the experimental trials to ensure that any modulation of pain by the vibration itself is consistent across calibration and experimental trials. Ratings of CSneutral trials from the experimental phase are not relevant to the research question and are therefore not analyzed.Experimental TrialsBased on the experimental setup discussed previously, and given the pairing of CSs and USs, the experiment for a participant can theoretically consist of five different types of trials:Training trials: Each training trial consists of one CS, with each of the three CS types used in different trials. There is no electrocutaneous stimulation (i.e., US) presented. These trials are conducted to familiarize the participants with the locations of the CS tactors. Baseline trials: The baseline trials consist of two combinations of stimulations: a CS+ with a simultaneous UStest and a CS− with a simultaneous UStest. These trials are used to record baseline pain ratings of participants before they are conditioned to associate the painful US with a particular CS.Acquisition or learning trials: These trials consist of two combinations of stimulations: a CS+ with an UShigh and a CS− with an USlow, and are meant to condition participants to associate painful US to CS+ and vice versa.Test trials: These trials are the same as the two baseline trials: a CS+ with an UStest and a CS− with an UStest, and are meant to record pain ratings of participants to test whether they have associated the painful US with CS+ and vice versa.Irrelevant trials: These trials consist of a CSneutral combined with an UStest stimuli. These trials are noninformative and are included to satisfy the assumptions of the analytical approach; they are included only to achieve consistency in the time gaps between baseline or test trials. Observed VariablesThe participants are requested to provide two reports on each trial. First, they rate the stimulation event on the Sensation and Pain Rating Scale ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1093/pm/pnw221","ISSN":"15264637","PMID":"27688310","abstract":"Objective: Associative learning has been proposed as a mechanism behind the persistence of pain after tissue healing. The simultaneous occurrence of nociceptive and non-nociceptive input during acute injury mimics the pairings thought to drive classical conditioning effects. However, empirical evidence for classically conditioned allodynia is lacking. We aimed to manipulate pain thresholds with a classical conditioning procedure that used non-nociceptive somatosensory stimuli as conditioned stimuli (CS) and nociceptive stimuli as unconditioned stimuli. We also explored the influence of gender, depression, anxiety, negative affect, and pain catastrophizing on the main manipulation. Design: Thirty-four healthy humans participated in a differential classical conditioning procedure that used vibrotactile stimulations at two different locations as CS. In an acquisition phase, CS+ was paired with painful thermal stimulation, and CS- with nonpainful thermal stimulation. Heat pain threshold was assessed during paired heat-CS trials before and after acquisition. A 2 (time: 1 and 2) x 2 (condition: CS+ and CS-) repeated-measures analysis of variance compared pain thresholds before and after acquisition. Exploratory analyses explored the influence of gender, depression, anxiety, negative affect, and pain catastrophizing. Postexperiment questions investigated participants' awareness of the contingencies employed. Results: The classical conditioning procedure did not alter pain thresholds. Exploratory analyses did not reveal any influence of individual differences. Thirty of the 34 participants were unaware of the contingencies between stimuli. Conclusions: The results of this study provide no evidence that allodynia can be induced in healthy humans using a classical conditioning procedure with simultaneous timing.","author":[{"dropping-particle":"","family":"Madden","given":"Victoria J.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Russek","given":"Leslie N.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Harvie","given":"Daniel S.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Vlaeyen","given":"Johan W.S.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Moseley","given":"G. Lorimer","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Pain Medicine","id":"ITEM-1","issue":"7","issued":{"date-parts":[["2017"]]},"page":"1314-1325","title":"Classical conditioning fails to elicit allodynia in an experimental study with healthy humans","type":"article-journal","volume":"18"},"prefix":"SPARS; previously known as FESTNRS;","uris":["http://www.mendeley.com/documents/?uuid=23f7293f-50b8-4339-a826-9b8c24836fb4"]},{"id":"ITEM-2","itemData":{"DOI":"10.1016/j.jpain.2018.10.006","ISSN":"15288447","PMID":"30391525","abstract":"In experiments on pain, participants are frequently exposed to nonpainful and painful stimuli; however, the conventional pain-rating scales lack a nonpainful range and a clear point of transition from nonpainful to painful events. The Sensation and Pain Rating Scale (SPARS) assesses the full stimulus intensity range, extending from no sensation (rating: –50) to worst pain imaginable (rating: +50), and it explicitly identifies pain threshold (rating: 0). Here, we tested the SPARS in 2 experiments by using laser heat stimuli to establish its stimulus–response characteristics (Experiment 1, N = 19, 13 stimulus intensities applied 26 times each across a 1–4 J range), and compared it to 0 to 100 scales that assess nonpainful (0: no sensation, 100: pain) and painful (0: no pain, 100: worst pain imaginable) events (Experiment 2, N = 7, 9 stimulus intensities applied 36 times each across a 1.5–4.5 J range). Despite high inter- and intraindividual variations, we found a reasonably consistent curvilinear stimulus–response relationship (the curve flattens around pain threshold), with stable response characteristics across the range of the scale. The SPARS ratings transformed to a 0 to 100 range tended to be lower than the 0 to 100 pain rating scale in the noxious stimulus intensity range and greater than the 0 to 100 nonpainful sensation scale in the non-noxious stimulus range, likely reflecting differences in scale dimensionality. The SPARS overcomes limitations in scale range inherent to conventional pain rating scales. As such, it is well suited to experimental studies that must quantify a wider range of perceptual intensity or distinguish between painful and nonpainful events. Perspective: This article presents the stimulus–response characteristics of a new scale designed to allow participants to rate a range of nonpainful and painful stimuli. The scale could be useful for research that involves exposing participants to a range of stimulation intensities or requires a clear distinction between nonpainful and painful events.","author":[{"dropping-particle":"","family":"Madden","given":"Victoria J.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Kamerman","given":"Peter R.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Bellan","given":"Valeria","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Catley","given":"Mark J.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Russek","given":"Leslie N.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Camfferman","given":"Danny","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Moseley","given":"G. Lorimer","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Journal of Pain","id":"ITEM-2","issue":"4","issued":{"date-parts":[["2019"]]},"page":"472.e1-472.e12","publisher":"Elsevier Inc.","title":"Was that painful or nonpainful? The Sensation and Pain Rating Scale performs well in the experimental context","type":"article-journal","volume":"20"},"uris":["http://www.mendeley.com/documents/?uuid=158cf65d-2600-4940-8585-4da3f96fb859"]}],"mendeley":{"formattedCitation":"(SPARS; previously known as FESTNRS; Madden et al., 2017, 2019)","plainTextFormattedCitation":"(SPARS; previously known as FESTNRS; Madden et al., 2017, 2019)","previouslyFormattedCitation":"(SPARS; previously known as FESTNRS; Madden et al., 2017, 2019)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(SPARS; previously known as FESTNRS; Madden et al., 2017, 2019). The SPARS is anchored at -50 (no sensation), 0 (the exact point at which the feeling transitions to pain), and 50 (worst pain imaginable). The two distinct ranges for non-painful (-50 to -1) and painful (1 to 50) are clearly marked and explained to the participants. Participants are explicitly advised to make an initial decision about whether a trial was non-painful or painful before assigning a rating from the appropriate side of the scale, without selecting 0 on SPARS. Second, the participant indicates the location at which they feel the vibrotactile stimulus from the three options “ABOVE”, “BELOW”, and “SIDE”. This is only used to confirm that the participants are identifying the location of the stimuli correctly. Given that discrimination of the vibrotactile stimuli is necessary for differential learning, participants who fail to identify the location of the stimulus correctly in at least 75% of the trials are excluded and replaced by additional participants.Effect Size Measure and Test StatisticWe are interested in calculating whether the participants judged trials of CS+/ UStest and CS−/ UStest as painful or non-painful differently for baseline and test trials. For this purpose, we first convert the SPARS ratings to a binary variable: 0 for non-painful (-50 to -1 on SPARS) and 1 for painful (1 to 50 on SPARS). A rating of 0 on SPARS can neither be classified as painful nor as non-painful, therefore these are considered indeterminate and were marked as missing. Then, we pair two trials, a CS+/ UStest and a CS−/ UStest and calculate the difference between the corresponding binary variables. The resulting difference indicates whether the participant is rating CS+/ UStest and CS−/ UStest differently. The difference can result in three different values: 1 when the CS+/ UStest trial is rated as painful while the corresponding CS−/ UStest trial is rated as non-painful; −1 when the CS+/ UStest trial is rated as non-painful while the corresponding CS−/ UStest trial is rated as painful; and finally, 0 when both CS+/ UStest and CS−/ UStest trials are rated as painful or both are rated as non-painful. This difference value, calculated from a pair of trials, constitutes one measurement in our SCE. A simple mean difference (MD) effect size measure is calculated as the difference between the means of the difference values derived from the test trial pairs and the difference values derived from the baseline trial pairs. Due to the flexibility of RTs, this effect size measure can also be used as the test statistic ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1080/09602011.2013.818564","ISBN":"09602011 (ISSN)","ISSN":"14640694","PMID":"23865938","abstract":"Single-case experiments can be used to evaluate the effect of an intervention or treatment for a single entity. The internal validity and statistical conclusion validity of single-case experiments can be improved by incorporating randomisation in their design. In this article, we explain how to design randomised single-case phase and alternation studies as well as randomised simultaneous and sequential replication studies, and how to conduct randomisation tests for these designs. Advantages and limitations of randomisation tests are discussed. In order to not only determine the (non)randomness of an intervention effect, but also the magnitude of this effect, we propose to use an effect size index as a test statistic for the randomisation test. We illustrate this combination for the design and analysis of an ABAB phase study, using a free software package.","author":[{"dropping-particle":"","family":"Heyvaert","given":"Mieke","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Neuropsychological Rehabilitation","id":"ITEM-1","issue":"3-4","issued":{"date-parts":[["2014"]]},"page":"507-527","title":"Analysis of single-case data: Randomisation tests for measures of effect size","type":"article-journal","volume":"24"},"uris":["http://www.mendeley.com/documents/?uuid=2b7622b9-97a6-4dc8-8789-3f3716c9bcc5"]}],"mendeley":{"formattedCitation":"(Heyvaert & Onghena, 2014a)","plainTextFormattedCitation":"(Heyvaert & Onghena, 2014a)","previouslyFormattedCitation":"(Heyvaert & Onghena, 2014a)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Heyvaert & Onghena, 2014a). Single-Case Design In this section, we describe our considerations regarding which SCE design to use in our experiment. We discuss several initial design possibilities that were chosen by trial and error and conclude with a final design.Initial Design OptionsRandomized Block Design. Since each of our measurements requires a pair of trials, we immediately considered a randomized block design (RBD) for the experiment. In an RBD SCE, similar to an RBD in traditional group designs, the measurement occasions are divided into small blocks, with each block containing administrations of all treatment conditions ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1002/0470013192.bsa625","ISBN":"9780470860809","abstract":"Abstract A single-case design is an experimental design for a study in which one entity is observed repeatedly during a certain period under different levels of at least one independent variable. Single-case designs have a long tradition and growing impact in behavioral science. They are the designs of first choice if demonstration of an effect in a single case is aimed at or if a test of a theory in a single case is sufficient (or the only possibility), and they are most compatible with clinical practice. The systematic and purposive planning of interventions in single-case research represents the main difference with both observational time series research and qualitative case study research. In addition, single-case research can gain internal and statistical-conclusion validity by including randomization in the design. Two types of randomized single-case designs are presented: randomized alternation designs and randomized phase designs. Finally, external validity of single-case results can be demonstrated or tested by simultaneous or sequential replication and the corresponding simultaneous randomization tests and meta-analytic procedures.","author":[{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"collection-title":"Major Reference Works","container-title":"Encyclopedia of statistics in behavioral science","editor":[{"dropping-particle":"","family":"Everitt","given":"B","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Howell","given":"D","non-dropping-particle":"","parse-names":false,"suffix":""}],"id":"ITEM-1","issued":{"date-parts":[["2005","4","15"]]},"note":"From Duplicate 2 (Single‐case designs - Onghena, Patrick)\n\nFrom Duplicate 2 (Single-Case Designs - Onghena, Patrick)\n\ndoi:10.1002/0470013192.bsa625","page":"1850-1854","publisher":"John Wiley & Sons, Ltd","publisher-place":"Hoboken, NJ","title":"Single‐case designs","type":"chapter","volume":"4"},"uris":["http://www.mendeley.com/documents/?uuid=76f5ffc0-1aab-422c-8594-df5221dcce08"]}],"mendeley":{"formattedCitation":"(Onghena, 2005)","plainTextFormattedCitation":"(Onghena, 2005)","previouslyFormattedCitation":"(Onghena, 2005)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Onghena, 2005). For our study, a possible block consists of the two baseline (or test) trials, a CS+/ UStest and a CS−/ UStest, in random order. Hence, the experiment for a participant can consist of several blocks of baseline trial pairs, followed by a period of acquisition trials to condition the participants, followed by several blocks of test trial pairs. However, this design is immediately rejected, as an RBD SCE requires all treatment conditions to be applied inside a block. Since the effects of conditioning are acquired over a period of time and are expected to carry over to future trials, true alternation of treatment conditions is not possible in this experiment. AB Phase Design with In-Phase Acquisition. When we rejected the RBD, we realized that the experiment should consist of periods of baseline trial pairs and periods of test trial pairs. The simplest method to achieve this is using an AB phase design, with an A phase as the baseline condition and a subsequent B phase as the test condition ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"ISBN":"9780205474554","author":[{"dropping-particle":"","family":"Barlow","given":"D H","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Nock","given":"M K","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Hersen","given":"M","non-dropping-particle":"","parse-names":false,"suffix":""}],"edition":"3","id":"ITEM-1","issued":{"date-parts":[["2009"]]},"number-of-pages":"393","publisher":"Pearson/Allyn and Bacon","publisher-place":"Boston, MA","title":"Single case experimental designs: Strategies for studying behavior change","type":"book"},"uris":["http://www.mendeley.com/documents/?uuid=3f9cf20a-1f7e-4f61-b91c-a7cfa8573c37"]}],"mendeley":{"formattedCitation":"(Barlow et al., 2009)","plainTextFormattedCitation":"(Barlow et al., 2009)","previouslyFormattedCitation":"(Barlow et al., 2009)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Barlow et al., 2009). In favor of internal validity, the phase transition is preferably randomized. Each phase consists of several blocks of trials, each of which yields one measurement. Each measurement block in the baseline phase consists of k irrelevant trial pairs (two CSneutral/ UStest) and a baseline trial pair (a CS+/ UStest and a CS−/ UStest in random order). Similarly, each measurement block in the test phase consists of k acquisition trial pairs (a CS+/ UShigh and a CS−/ USlow in random order) followed by a test trial pair (a CS+/ UStest and a CS−/ UStest in random order). The number of irrelevant or acquisition trial pairs in each block, or k, is set based on the required level of acquisition. A lower k would mean we would need a lower number of trials to achieve a certain number of measurements, but would also typically result in weaker acquisition of associations, and vice versa for a higher k. Unfortunately, this design has low acquisition of the associations as there is no learning period. Additionally, RTs for AB phase designs require a large number of measurements to achieve sufficient statistical power ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.3758/s13428-018-1084-x","ISSN":"15543528","PMID":"30022457","abstract":"Single-case experimental designs (SCEDs) are increasingly used in fields such as clinical psychology and educational psychology for the evaluation of treatments and interventions in individual participants. The AB phase design, also known as the interrupted time series design, is one of the most basic SCEDs used in practice. Randomization can be included in this design by randomly determining the start point of the intervention. In this article, we first introduce this randomized AB phase design and review its advantages and disadvantages. Second, we present some data-analytical possibilities and pitfalls related to this design and show how the use of randomization tests can mitigate or remedy some of these pitfalls. Third, we demonstrate that the Type I error of randomization tests in randomized AB phase designs is under control in the presence of unexpected linear trends in the data. Fourth, we report the results of a simulation study investigating the effect of unexpected linear trends on the power of the randomization test in randomized AB phase designs. The implications of these results for the analysis of randomized AB phase designs are discussed. We conclude that randomized AB phase designs are experimentally valid, but that the power of these designs is sufficient only for large treatment effects and large sample sizes. For small treatment effects and small sample sizes, researchers should turn to more complex phase designs, such as randomized ABAB phase designs or randomized multiple-baseline designs.","author":[{"dropping-particle":"","family":"Michiels","given":"Bart","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Behavior Research Methods","id":"ITEM-1","issue":"6","issued":{"date-parts":[["2019"]]},"page":"2454-2476","publisher":"Behavior Research Methods","title":"Randomized single-case AB phase designs: Prospects and pitfalls","type":"article-journal","volume":"51"},"uris":["http://www.mendeley.com/documents/?uuid=df9e6256-20e5-4650-b35e-43c7d03b67ed"]},{"id":"ITEM-2","itemData":{"author":[{"dropping-particle":"","family":"Ferron","given":"John","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Ware","given":"William","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"The Journal of Experimental Education","id":"ITEM-2","issue":"2","issued":{"date-parts":[["1995"]]},"page":"167-178","title":"Analyzing single-case data: The power of randomization tests","type":"article-journal","volume":"63"},"uris":["http://www.mendeley.com/documents/?uuid=10969372-d714-4dd9-be5d-56f2952ac89a"]}],"mendeley":{"formattedCitation":"(Ferron & Ware, 1995; Michiels & Onghena, 2019)","plainTextFormattedCitation":"(Ferron & Ware, 1995; Michiels & Onghena, 2019)","previouslyFormattedCitation":"(Ferron & Ware, 1995; Michiels & Onghena, 2019)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Ferron & Ware, 1995; Michiels & Onghena, 2019). As a result, the experiment for a participant would need a very large number of trials over a significantly long time to ensure both high acquisition and enough measurements. As a result, this design is rejected in favor of a slightly modified AB phase design. A similar ABAB phase design is also rejected due to the potentially large number of trials required and possibility of carry-over effects between phases. Final DesignThe final design combines elements from both previous designs: an AB phase design with both out-of-phase and in-phase learning. The baseline phase for this design contains several pairs of baseline trial pairs (a CS+/ UStest and a CS−/ UStest in random order), followed by a period of learning with only acquisition trial pairs (a CS+/ UShigh and a CS−/ USlow in random order). Finally, the test phase includes test trial pairs (a CS+/ UStest and a CS−/ UStest in random order) with a few acquisition trial pairs in between at regular intervals to reinforce the associations and hence prevent extinction. The time of onset of the test phase is randomized. The experiment starts with a few training trials before the baseline phase. The number of trials and the number of participants are to be decided based on a power study and some pilot experiments. However, the guidelines for phase designs by Kratochwill et al. ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"ISBN":"2072366658","abstract":"In an effort to expand the pool of scientific evidence available for review, the What Works Clearinghouse (WWC) assembled a panel of national experts in single-case design (SCD) and analysis to draft SCD Standards. In this paper, the panel provides an overview of SCDs, specifies the types of questions that SCDs are designed to answer, and discusses the internal validity of SCDs. The panel then proposes SCD Standards to be implemented by the WWC. The Standards are bifurcated into Design and Evidence Standards (see Figure 1). The Design Standards evaluate the internal validity of the design. Reviewers assign the categories of Meets Standards, Meets Standards with Reservations and Does not Meet Standards to each study based on the Design Standards. Reviewers trained in visual analysis will then apply the Evidence Standards to studies that meet standards (with or without reservations), resulting in the categorization of each outcome variable as demonstrating Strong Evidence, Moderate Evidence, or No Evidence.","author":[{"dropping-particle":"","family":"Kratochwill","given":"T. R.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Hitchcock","given":"J","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Horner","given":"Robert H","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Levin","given":"J R","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Odom","given":"S L","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Rindskopf","given":"D M","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Shadish","given":"W R","non-dropping-particle":"","parse-names":false,"suffix":""}],"id":"ITEM-1","issued":{"date-parts":[["2010"]]},"title":"Single-case design technical documentation","type":"article"},"suppress-author":1,"uris":["http://www.mendeley.com/documents/?uuid=5dcf7b6e-f904-44b1-9c41-015a9c911322"]}],"mendeley":{"formattedCitation":"(2010)","plainTextFormattedCitation":"(2010)","previouslyFormattedCitation":"(2010)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(2010) recommend at least five measurements in both baseline and test phases. Since we are also curious about any increase or decrease in acquisition over time, we decide to include at least 15 measurements in the test phase. Due to the use of specialized equipment and individual calibration, multiple participants cannot be tested at the same time. Hence, simultaneous replication using a multiple baseline design (MBD), which is able to control for environmental confounding factors, is not possible ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"ISBN":"9780205474554","author":[{"dropping-particle":"","family":"Barlow","given":"D H","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Nock","given":"M K","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Hersen","given":"M","non-dropping-particle":"","parse-names":false,"suffix":""}],"edition":"3","id":"ITEM-1","issued":{"date-parts":[["2009"]]},"number-of-pages":"393","publisher":"Pearson/Allyn and Bacon","publisher-place":"Boston, MA","title":"Single case experimental designs: Strategies for studying behavior change","type":"book"},"uris":["http://www.mendeley.com/documents/?uuid=3f9cf20a-1f7e-4f61-b91c-a7cfa8573c37"]},{"id":"ITEM-2","itemData":{"ISBN":"978-0-19-534188-1 (Paperback)","abstract":"Single-case research has played an important role in developing and evaluating interventions that are designed to alter a particular facet of human functioning. Now thoroughly updated in its second edition, acclaimed author Alan Kazdin's Single-Case Research Designs provides a notable contrast to the quantitative methodology approach that pervades the biological and social sciences. While focusing on widely applicable methodologies for evaluating interventions—such as treatment, education, and psychotherapy using applied behavior analysis—this revised edition also encompasses a broader range of research areas that use single-case designs demonstrating the pertinence of this methodology in various disciplines, from psychology and medicine to business and industry. The following aspects are new to this edition; Offers new options in experimental design, presenting combinations of designs that increase the range of questions that can be asked about alternative interventions; Details the underlying rationale and methods of evaluating intervention effects through visual inspection in the area of data evaluation; Provides an expanded description of methods (e.g., assessment) and a greater range of examples; Includes an appendix at the end of the book to encourage discussion of the challenges, advances, and dilemmas of statistical evaluation and visual inspection in the design. This well-written, clear, and thoroughly updated text is ideal for practitioners, instructors, and students alike. (PsycINFO Database Record (c) 2016 APA, all rights reserved)","author":[{"dropping-particle":"","family":"Kazdin","given":"Alan E","non-dropping-particle":"","parse-names":false,"suffix":""}],"edition":"2","id":"ITEM-2","issued":{"date-parts":[["2011"]]},"number-of-pages":"xi, 452-xi, 452","publisher":"Oxford University Press","publisher-place":"New York, NY","title":"Single-case research designs: Methods for clinical and applied settings","type":"book"},"uris":["http://www.mendeley.com/documents/?uuid=0bf25535-0ac8-4a4e-9baf-8d687854b102"]}],"mendeley":{"formattedCitation":"(Barlow et al., 2009; Kazdin, 2011)","plainTextFormattedCitation":"(Barlow et al., 2009; Kazdin, 2011)","previouslyFormattedCitation":"(Barlow et al., 2009; Kazdin, 2011)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Barlow et al., 2009; Kazdin, 2011). Instead, the experiment is to be run as a sequentially replicated AB phase design experiment. Randomization Scheme and RTThe design is randomized using intervention start point randomization for each participant ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1080/00223980.1975.9923926","ISSN":"0022-3980","author":[{"dropping-particle":"","family":"Edgington","given":"Eugene S","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Journal of Psychology","id":"ITEM-1","issue":"1","issued":{"date-parts":[["1975","5","1"]]},"note":"Last updated - 2013-02-21","page":"57","publisher":"Journal Press, etc.","publisher-place":"Provincetown, Mass., etc.","title":"Randomization tests for one-subject operant experiments","type":"article-journal","volume":"90"},"uris":["http://www.mendeley.com/documents/?uuid=b8cbd2f4-cfe3-4ff2-81ed-267a4033f315"]}],"mendeley":{"formattedCitation":"(Edgington, 1975)","plainTextFormattedCitation":"(Edgington, 1975)","previouslyFormattedCitation":"(Edgington, 1975)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Edgington, 1975). In this scheme, the total number of measurements and the minimum number of measurements in each phase is decided beforehand, and the intervention can start at any time point that satisfies these restrictions. Therefore, if the number of measurements is N, and the minimum number of measurements in A and B phase are a and b respectively, the number of possible randomizations is r = N – a – b + 1. For P participants with the same randomization scheme, the total number of randomizations for the replicated experiment is rP. We conduct a single RT for all participants combined based on these rP randomizations. The null hypothesis for this RT is that no difference exists between the baseline phase measurements and test phase measurements for all participants. As discussed previously, the measurements represent whether participants rate CS+/ UStest trials as painful more frequently than CS−/ UStest trials. Since the Pavlovian conditioning procedure is aimed at participants perceiving the CS+/ UStest as more painful, the RT is one-sided with the alternate hypothesis being that the test phase measurements are higher than the baseline phase measurements for at least one participant. This RT can be conducted with the average (across participants) of the MD effect size measure discussed previously as the combined test statistic.We use the Shiny SCDA (Single-Case Data Analysis) web app for SCEs to randomize and analyze the experiment ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"author":[{"dropping-particle":"","family":"De","given":"Tamal Kumar","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Michiels","given":"Bart","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Vlaeyen","given":"Johan W S","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"id":"ITEM-1","issued":{"date-parts":[["2020"]]},"number":"Version 2.7","title":"Shiny SCDA","type":"article"},"uris":["http://www.mendeley.com/documents/?uuid=ff1167ee-c172-4d50-9512-1ab3115e6df4"]}],"mendeley":{"formattedCitation":"(De, Michiels, Vlaeyen, et al., 2020)","plainTextFormattedCitation":"(De, Michiels, Vlaeyen, et al., 2020)","previouslyFormattedCitation":"(De, Michiels, Vlaeyen, et al., 2020)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(De, Michiels, Vlaeyen, et al., 2020). Whereas this web app does not include an option for simultaneously replicated AB phase design, it does include an MBD option. The MBD option in Shiny SCDA uses the Koehler-Levin regulated randomization procedure ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1080/17518423.2016.1197708","ISSN":"17518431","abstract":"© 2016 Taylor & FrancisIn three simulation investigations, we examined the statistical properties of several different randomization-test procedures for analyzing the data from single-case multiple-baseline intervention studies. Two procedures (Wampold–Worsham and Revusky) are associated with single fixed intervention start points and three are associated with randomly determined intervention start points. Of the latter three, one (Koehler–Levin) is an existing procedure that has been previously examined and the other two (modified Revusky and restricted Marascuilo–Busk) are modifications and extensions of existing procedures. All five procedures were found to maintain their Type I error probabilities at acceptable levels. In most of the conditions investigated here, two of the random start-point procedures (Koehler–Levin and restricted Marascuilo–Busk) were more powerful than the others with respect to detecting immediate abrupt intervention effects. For designs in which it is not possible to include the same series lengths for all cases, either the modified Revusky or restricted Marascuilo–Busk procedure is recommended.","author":[{"dropping-particle":"","family":"Levin","given":"Joel R.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Ferron","given":"John M.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Gafurov","given":"Boris S.","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Developmental Neurorehabilitation","id":"ITEM-1","issue":"5","issued":{"date-parts":[["2018"]]},"page":"290-311","publisher":"Taylor & Francis","title":"Comparison of randomization-test procedures for single-case multiple-baseline designs","type":"article-journal","volume":"21"},"uris":["http://www.mendeley.com/documents/?uuid=ae1f7a7e-dd85-43c8-bfc5-ce1f32088039"]}],"mendeley":{"formattedCitation":"(Levin et al., 2018)","plainTextFormattedCitation":"(Levin et al., 2018)","previouslyFormattedCitation":"(Levin et al., 2018)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Levin et al., 2018), which, when using an identical set of possible start points for all participants, is analogous to our randomization scheme. Hence, we can both randomly select test phase start points and run the RT in Shiny SCDA. Additionally, we can plot the observed data for visual analysis in Shiny SCDA. Pilot TestsWe ran several pilot tests to estimate possible effect sizes and to test possible design choices. We first tested nine participants under slight variations of our initial design choice. Later, after a simulated power study and adjustments to the design, we tested another four participants. We analyzed these four tests using visual analysis and an RT in Shiny SCDA. These four tests were, however, not randomized, and the test phase for all four participants started at the tenth measurement occasion. However, for the purposes of demonstration, we ignored the assumption of randomization. We will discuss the results from these pilot tests, and the final four tests in particular in the Results section. There were two important takeaways from the first nine pilot tests that were very useful for the design of the power study. First, the observed MD effect sizes were extremely small. The average effect size from the first nine tests was slightly negative at -0.037, with a maximum of 0.143 and a minimum of -0.400. Second, the pilot tests also revealed difficulties in running the experiment for more than 30-35 minutes for a participant. Considering each trial took around 15 seconds, this gave us a maximum of around 140 trials.Power StudyTo ensure sufficient statistical power for our RT, we needed to first estimate power for different values of number of measurements (N) and number of participants (P), and then choose sufficiently high values of N and P for the experiment. Ideally, we would want to select the maximum N possible within the limits of how long an experiment can be reasonably run. This strategy presents us with two advantages. First, increasing N should result in reduction in the variability of the estimate of effect size. Second, maximizing N should allow us to achieve sufficient power with lower P, which directly equates to lower cost for the experiment.We used the Monte Carlo method used by Ferron and Onghena ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1080/00220973.1996.9943805","ISBN":"0022-0973","ISSN":"19400683","abstract":"Monte Carlo methods were used to estimate the power of randomization tests used with single-case designs involving the random assignment of treatments to phases. The design studied involved 2 treatments and 6 phases. The power was studied for 6 standardized effect sizes (0, .2, .5, .8, 1.1, and 1.4), 4 levels of autocorrelation (1st order autocorrelation coefficients of -.3, 0, .3, and .6), and 5 different phase lengths (4, 5, 6, 7, and 8 observations). Power was estimated for each condition by simulating 10,000 experiments. The results showed an adequate level of power (> .80) when effect sizes were large (1.1 and 1.4), phase lengths exceeded 5, and autocorrelation was not negative.","author":[{"dropping-particle":"","family":"Ferron","given":"John","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Journal of Experimental Education","id":"ITEM-1","issue":"3","issued":{"date-parts":[["1996"]]},"page":"231-239","title":"The power of randomization tests for single-case phase designs","type":"article-journal","volume":"64"},"suppress-author":1,"uris":["http://www.mendeley.com/documents/?uuid=a041ea39-019c-41f1-84e0-80ff61fccbc1"]}],"mendeley":{"formattedCitation":"(1996)","plainTextFormattedCitation":"(1996)","previouslyFormattedCitation":"(1996)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(1996) to estimate power. In this method, several datasets are simulated under a set of simulation conditions. The proportion of these simulated datasets in which the RT leads to a rejection of the null hypothesis gives an estimate of statistical power for the given set of simulation conditions. A simulation study of such complexity is both difficult to program and computationally intensive to execute. Fortunately, we were able to modify and repurpose R code used by De, Michiels, Tanious, et al. ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.3758/s13428-019-01320-3","ISSN":"15543528","PMID":"31898296","abstract":"Single-case experiments have become increasingly popular in psychological and educational research. However, the analysis of single-case data is often complicated by the frequent occurrence of missing or incomplete data. If missingness or incompleteness cannot be avoided, it becomes important to know which strategies are optimal, because the presence of missing data or inadequate data handling strategies may lead to experiments no longer “meeting standards” set by, for example, the What Works Clearinghouse. For the examination and comparison of strategies to handle missing data, we simulated complete datasets for ABAB phase designs, randomized block designs, and multiple-baseline designs. We introduced different levels of missingness in the simulated datasets by randomly deleting 10%, 30%, and 50% of the data. We evaluated the type I error rate and statistical power of a randomization test for the null hypothesis that there was no treatment effect under these different levels of missingness, using different strategies for handling missing data: (1) randomizing a missing-data marker and calculating all reference statistics only for the available data points, (2) estimating the missing data points by single imputation using the state space representation of a time series model, and (3) multiple imputation based on regressing the available data points on preceding and succeeding data points. The results are conclusive for the conditions simulated: The randomized-marker method outperforms the other two methods in terms of statistical power in a randomization test, while keeping the type I error rate under control.","author":[{"dropping-particle":"","family":"De","given":"Tamal Kumar","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Michiels","given":"Bart","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Tanious","given":"René","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Behavior Research Methods","id":"ITEM-1","issue":"3","issued":{"date-parts":[["2020"]]},"page":"1355-1370","title":"Handling missing data in randomization tests for single-case experiments: A simulation study","type":"article-journal","volume":"52"},"suppress-author":1,"uris":["http://www.mendeley.com/documents/?uuid=3f81dd4a-3b90-4d7c-8466-29e57b7ea490"]}],"mendeley":{"formattedCitation":"(2020)","plainTextFormattedCitation":"(2020)","previouslyFormattedCitation":"(2020)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(2020) for this study. Simulation ConditionsThe following three simulation conditions were varied for this power study:Effect size: Based on the low effect sizes observed in the pilot tests, we simulated MD effect sizes of 0.1, 0.2, 0.3, 0.4, and 0.5 for the simulated observed data.Number of measurements: We decided on a minimum of five measurements in the baseline phase and a minimum of 15 measurements in the test phase. As a result, the experiment needs more than 20 measurements. However, from the pilot tests it was evident that an experiment with more than 140 trials (70 trial pairs) was not feasible. Considering around 30 trials are required for the training and learning periods, and a few more acquisition trails for reinforcement during test phase, it was difficult to have more than 40 measurements (80 trials). Hence, we used 25, 30, 35, and 40 measurements for simulated data. Number of participants: Since the pilot tests revealed a small effect size, and the number of measurements is also limited, to ensure high power we considered a large range of participant count at 10, 20, 30, 40, and 50. Other Simulation ParametersFor the power study, we wanted to simulate observed values that were similar to the experiment. For the baseline, we assumed a symmetric distribution around 0 for the SPARS rating. Therefore, the painful/non-painful ratings were expected to be 0s and 1s equally for both CS+/ UStest and CS−/ UStest trials. Hence, an observed value corresponding to a trial pair in the baseline was expected to be 1 with 25% probability, -1 with 25% probability, and 0 with 50% probability. We simulated observed values as 1, -1, and 0 with these probabilities. For the test phase, we increased the probability of 1 by half the selected effect size and decreased the probability of -1 by half the selected effect size. This resulted in an expected MD effect size equal to the selected effect size. Since the number of randomizations for the RT was huge, we simulated Monte Carlo RTs with 1000 randomizations ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1080/00223980.1969.10543491","ISSN":"0022-3980","author":[{"dropping-particle":"","family":"Edgington","given":"Eugene S","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"The Journal of Psychology","id":"ITEM-1","issue":"2","issued":{"date-parts":[["1969","7","1"]]},"note":"doi: 10.1080/00223980.1969.10543491","page":"143-149","publisher":"Routledge","title":"Approximate randomization tests","type":"article-journal","volume":"72"},"uris":["http://www.mendeley.com/documents/?uuid=ebadd319-bf20-4e7a-84b0-4ffa7de72276"]}],"mendeley":{"formattedCitation":"(Edgington, 1969)","plainTextFormattedCitation":"(Edgington, 1969)","previouslyFormattedCitation":"(Edgington, 1969)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Edgington, 1969). For estimating power, we simulated 10000 datasets for each set of simulation conditions. Finally, we used a 5% level of significance for the simulated RTs.The simulations were run on supercomputer nodes at the Flemish Supercomputer Center (Leuven, Belgium). This allowed testing more simulation conditions and achieve high accuracy simulating a large number of datasets for each simulation condition; however, the simulations can also be run at a smaller scale on a personal computer. ResultsPower AnalysisThe results from the power study (Table 1) revealed that due to the relatively small effect sizes and restricted number of measurements, the number of participants need to be high to achieve 80% power. If we restrict the number of measurements to 30, which allows sufficient acquisition trials for learning and reinforcement within 30 minutes, 30 participants result in sufficient power even with a moderate effect size. Table 1Estimated Power Simulated Using Different Values for Effect Size, Number of Measurements, and Number of Participants.No. of measurementsNo. of participantsEffect size0.10.20.30.40.5251010.319.032.248.666.1 2013.429.351.474.490.0 3016.438.866.187.997.7 4018.947.577.494.899.5 5022.254.785.197.999.9301013.025.945.066.183.9 2017.942.070.690.898.5 3021.954.986.097.999.9 4026.465.292.799.6100.0 5030.073.496.699.9100.0351014.331.455.077.492.7 2021.051.481.096.699.7 3027.465.593.399.7100.0 4032.877.197.599.9100.0 5037.484.799.1100.0100.0401015.436.063.984.996.3 2023.658.188.498.6100.0 3030.774.096.899.9100.0 4037.084.699.2100.0100.0 5042.890.499.8100.0100.0Based on these results, we decided to run the final set of pilot tests with 30 measurements. We decided on six training trials (two trials for each type of CS) before the baseline phase, 24 acquisition trials between the baseline and test phases, and additionally one acquisition trial pair for reinforcement after two test trial pairs during the test phase. With a minimum of five measurements in the baseline phase, and a minimum of 15 measurements in the test phase, this design allows for 11 possible randomizations. Depending on the number of measurements in the test phase which will vary based on the test phase start point selected, the experiment could theoretically consist of 104 to 114 trials. This is the design we intend to follow in the final experiment with 30 participants (Figure 2).Figure 2Final Design With 30 Measurements.[INSERT FIGURE 2 HERE]Pilot TestsAs mentioned previously, the initial nine pilot tests resulted in extremely small (and a few negative) effect sizes. The average MD effect size was -0.037, with a maximum of 0.143 and a minimum of -0.400. The low effect sizes indicated that the final design would need a large number of measurements and participants to achieve sufficient power in the RT. The first seven of these pilot tests consisted of 10-20 measurements each, which seemed too few. On the other hand, the last two pilot tests out of these consisted of 238 trials each. The feedback from both the experimenters and participants was that these tests were too long. These results influenced the decision to limit the number of trails to 140, remove irrelevant trial pairs from the baseline phase, and lower the number of acquisition trail pairs in the treatment phase. Figure 3Plot of Observed Scores Obtained From the Initial Nine Participants in the Pilot Tests.[INSERT FIGURE 3 HERE]The later four pilot tests were run using the design parameters we decided on after the power study. The average MD effect size for these participants was 0.057, with a maximum of 0.476 and a minimum of -0.250. Visual analysis (Figure 4) revealed that the first, third, and fourth participant did not seem to show any sign of conditioning. However, the second participant seemed to show significant conditioning effects. This is also confirmed by the MD effect size for the second participant (0.476). Finally, a Monte Carlo RT with 1000 randomizations resulted in a p-value of 0.112. Hence, the null hypothesis of the RT could not be rejected at a 5% level of significance. Figure 4Plot of Observed Scores Obtained From the Final Four Participants in the Pilot Tests.[INSERT FIGURE 4 HERE]DiscussionThe power analysis and pilot test results confirm that the SCE design developed for this study can be effectively used to test the effect of classical conditioning on pain thresholds. The power study provides strong evidence that this design results in sufficient power if the number of measurements and participants are chosen correctly. The results from the final four pilot tests were encouraging. Even though the RT lacked power due to the small number of participants, the p-value was low. The visual analysis also seemed to suggest a large effect for at least one participant. The final study using this protocol was not conducted immediately, due to lack of resources at the time. However, we hope to conduct this study as soon as the opportunity arises. Meanwhile, it seemed that the discussions regarding the SCE design and preparations for the study might be useful for other researchers developing similar protocols. Therefore, we decided to prepare this manuscript.The final design suffers from a few limitations. The first limitation is the observed variable defined by us, which only yields values of -1, 0, and 1. Unfortunately, this restricts variation in observed data and can cause duplicates in the randomization distribution, which can affect power. An alternative is to use the difference between SPARS ratings from CS+/ UStest and CS−/ UStest trial pairs. However, this would require a slightly different hypothesis, which would not clarify whether classical conditioning can affect pain thresholds specifically.The second limitation is due to the properties of the AB phase design. RTs using randomization of intervention start points in AB phase designs are known to lack power at lower sample sizes ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.3758/s13428-018-1084-x","ISSN":"15543528","PMID":"30022457","abstract":"Single-case experimental designs (SCEDs) are increasingly used in fields such as clinical psychology and educational psychology for the evaluation of treatments and interventions in individual participants. The AB phase design, also known as the interrupted time series design, is one of the most basic SCEDs used in practice. Randomization can be included in this design by randomly determining the start point of the intervention. In this article, we first introduce this randomized AB phase design and review its advantages and disadvantages. Second, we present some data-analytical possibilities and pitfalls related to this design and show how the use of randomization tests can mitigate or remedy some of these pitfalls. Third, we demonstrate that the Type I error of randomization tests in randomized AB phase designs is under control in the presence of unexpected linear trends in the data. Fourth, we report the results of a simulation study investigating the effect of unexpected linear trends on the power of the randomization test in randomized AB phase designs. The implications of these results for the analysis of randomized AB phase designs are discussed. We conclude that randomized AB phase designs are experimentally valid, but that the power of these designs is sufficient only for large treatment effects and large sample sizes. For small treatment effects and small sample sizes, researchers should turn to more complex phase designs, such as randomized ABAB phase designs or randomized multiple-baseline designs.","author":[{"dropping-particle":"","family":"Michiels","given":"Bart","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Onghena","given":"Patrick","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Behavior Research Methods","id":"ITEM-1","issue":"6","issued":{"date-parts":[["2019"]]},"page":"2454-2476","publisher":"Behavior Research Methods","title":"Randomized single-case AB phase designs: Prospects and pitfalls","type":"article-journal","volume":"51"},"uris":["http://www.mendeley.com/documents/?uuid=df9e6256-20e5-4650-b35e-43c7d03b67ed"]}],"mendeley":{"formattedCitation":"(Michiels & Onghena, 2019)","plainTextFormattedCitation":"(Michiels & Onghena, 2019)","previouslyFormattedCitation":"(Michiels & Onghena, 2019)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Michiels & Onghena, 2019). AB phase designs do not satisfy the guidelines set by Kratochwill et al. ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"ISBN":"2072366658","abstract":"In an effort to expand the pool of scientific evidence available for review, the What Works Clearinghouse (WWC) assembled a panel of national experts in single-case design (SCD) and analysis to draft SCD Standards. In this paper, the panel provides an overview of SCDs, specifies the types of questions that SCDs are designed to answer, and discusses the internal validity of SCDs. The panel then proposes SCD Standards to be implemented by the WWC. The Standards are bifurcated into Design and Evidence Standards (see Figure 1). The Design Standards evaluate the internal validity of the design. Reviewers assign the categories of Meets Standards, Meets Standards with Reservations and Does not Meet Standards to each study based on the Design Standards. Reviewers trained in visual analysis will then apply the Evidence Standards to studies that meet standards (with or without reservations), resulting in the categorization of each outcome variable as demonstrating Strong Evidence, Moderate Evidence, or No Evidence.","author":[{"dropping-particle":"","family":"Kratochwill","given":"T. R.","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Hitchcock","given":"J","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Horner","given":"Robert H","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Levin","given":"J R","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Odom","given":"S L","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Rindskopf","given":"D M","non-dropping-particle":"","parse-names":false,"suffix":""},{"dropping-particle":"","family":"Shadish","given":"W R","non-dropping-particle":"","parse-names":false,"suffix":""}],"id":"ITEM-1","issued":{"date-parts":[["2010"]]},"title":"Single-case design technical documentation","type":"article"},"suppress-author":1,"uris":["http://www.mendeley.com/documents/?uuid=5dcf7b6e-f904-44b1-9c41-015a9c911322"]}],"mendeley":{"formattedCitation":"(2010)","plainTextFormattedCitation":"(2010)","previouslyFormattedCitation":"(2010)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(2010) without multiple replications. Since we are not sure how quickly the effect of our conditioning is reversed, we cannot use phase designs with more phase changes, such as the ABAB phase design. Due to the requirement of specialized equipment, we cannot use an MBD. Critically, we cannot increase the number of measurements due to time constraints. Therefore, we have to rely on sequential replications for both validity and statistical power. The power study for this design also presents certain limitations. We used only one possible distribution of the SPARS ratings to simulate our observed data. While the assumption of a symmetric distribution around 0 is not unreasonable, with more pilot data, it might be possible to simulate using a distribution that resembles the observed data. We also did not account for any variability in effect size across participants. Instead, we simulated an equal effect size for all participants. However, we believe these are reasonable assumptions given the scope of our study. Finally, we conducted Monte Carlo RTs for both the power study and the pilot data. As discussed previously, the number of possible randomizations for this design is rP, where r denotes the number of possible randomizations for one participant, and P denotes the number of participants. Even for the smaller scale of the pilot data, computing 114 possible randomizations would have been extremely costly. Monte Carlo RTs present a simple alternative to this computation cost while maintaining sufficient statistical power ADDIN CSL_CITATION {"citationItems":[{"id":"ITEM-1","itemData":{"DOI":"10.1080/00223980.1969.10543491","ISSN":"0022-3980","author":[{"dropping-particle":"","family":"Edgington","given":"Eugene S","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"The Journal of Psychology","id":"ITEM-1","issue":"2","issued":{"date-parts":[["1969","7","1"]]},"note":"doi: 10.1080/00223980.1969.10543491","page":"143-149","publisher":"Routledge","title":"Approximate randomization tests","type":"article-journal","volume":"72"},"uris":["http://www.mendeley.com/documents/?uuid=ebadd319-bf20-4e7a-84b0-4ffa7de72276"]},{"id":"ITEM-2","itemData":{"ISSN":"00359246","abstract":"[The use of Monte Carlo test procedures for significance testing, with smaller reference sets than are now generally used, is advocated. It is shown that, for given α = 1/n, n a positive integer, the power of the Monte Carlo test procedure is a monotone increasing function of the size of the reference set, the limit of which is the power of the corresponding uniformly most powerful test. The power functions and efficiency of the Monte Carlo test to the uniformly most powerful test are discussed in detail for the case where the test criterion is N(γ. 1). The cases when the test criterion is Student's t-statistic and when the test statistic is exponentially distributed are considered also.]","author":[{"dropping-particle":"","family":"Hope","given":"Adery C A","non-dropping-particle":"","parse-names":false,"suffix":""}],"container-title":"Journal of the Royal Statistical Society. Series B (Methodological)","id":"ITEM-2","issue":"3","issued":{"date-parts":[["1968"]]},"page":"582-598","publisher":"[Royal Statistical Society, Wiley]","title":"A simplified Monte Carlo significance test procedure","type":"article-journal","volume":"30"},"uris":["http://www.mendeley.com/documents/?uuid=0f686ba0-e85d-4051-927b-8d05ab5cc267"]}],"mendeley":{"formattedCitation":"(Edgington, 1969; Hope, 1968)","plainTextFormattedCitation":"(Edgington, 1969; Hope, 1968)","previouslyFormattedCitation":"(Edgington, 1969; Hope, 1968)"},"properties":{"noteIndex":0},"schema":"https://github.com/citation-style-language/schema/raw/master/csl-citation.json"}(Edgington, 1969; Hope, 1968). Hence, we intend to conduct a Monte Carlo RT in the final experiment.As introduced earlier, this design presents certain advantages over traditional group study designs. Single-case designs are a better match for studying within-person changes, because they allow detailed insight into within-individual processes rather than assuming that the response of all individuals in a group is consistent. Additionally, these designs typically require a smaller number of participants. This allows for a lower overall cost and is particularly important for pain studies because it can be difficult to recruit participants.ConclusionIn this manuscript, we described how we used trial and error to design an SCE testing whether classical conditioning can affect pain thresholds. We used a sequentially replicated AB phase design and conducted a simulated power study to determine sample size. We decided on 30 participants and 30 measurements per participant. Finally, we ran some pilot tests using our design. While the results from the pilot tests were inconclusive, they were sufficiently encouraging that we plan to conduct the full study in the near future.Acknowledgements[Deleted for anonymous review]Data AvailabilityThe data and R code used in this study are openly available on Open Science Foundation at https://osf.io/d9mfn/?view_only=6b9bd4580dbf42b4952e551972f48c68.ReferencesADDIN Mendeley Bibliography CSL_BIBLIOGRAPHY Adams, D. C., & Anthony, C. D. (1996). Using randomization techniques to analyse behavioural data. Animal Behaviour, 51(4), 733–738. https://doi.org/https://doi.org/10.1006/anbe.1996.0077Barlow, D. H., Nock, M. K., & Hersen, M. (2009). Single case experimental designs: Strategies for studying behavior change (3rd ed.). Pearson/Allyn and Bacon.Bouwmeester, S., & Jongerling, J. (2020). Power of a randomization test in a single case multiple baseline AB design. PLoS ONE, 15(2), 1–21. https://doi.org/10.1371/journal.pone.0228355Breivik, H., Collett, B., Ventafridda, V., Cohen, R., & Gallacher, D. (2006). Survey of chronic pain in Europe: Prevalence, impact on daily life, and treatment. European Journal of Pain (London, England), 10(4), 287–333. https://doi.org/10.1016/j.ejpain.2005.06.009Busk, P. L., & Marascuilo, L. A. (1988). Autocorrelation in single-subject research: A counterargument to the myth of no autocorrelation. Behavioral Assessment, 10(3), 229–242.Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Routledge. https://doi.org/10.4324/9780203771587Costa, L. da C. M., Maher, C. G., McAuley, J. H., Hancock, M. J., Herbert, R. D., Refshauge, K. M., & Henschke, N. (2009). Prognosis for patients with chronic low back pain: Inception cohort study. BMJ, 339, b3829. https://doi.org/10.1136/bmj.b3829Dancer Design. (n.d.). Tactor. http://www.dancerdesign.co.uk/tactor.htmlDe, T. K., Michiels, B., Tanious, R., & Onghena, P. (2020). Handling missing data in randomization tests for single-case experiments: A simulation study. Behavior Research Methods, 52(3), 1355–1370. https://doi.org/10.3758/s13428-019-01320-3De, T. K., Michiels, B., Vlaeyen, J. W. S., & Onghena, P. (2020). Shiny SCDA (Version 2.7). https://ppw.kuleuven.be/mesrg/software-and-apps/shiny-scdaDigitimer Limited. (n.d.). DS7A High Voltage Constant Current Stimulator. https://www.digitimer.com/product/human-neurophysiology/peripheral-stimulators/ds7a-ds7ah-hv-current-stimulator/Edgington, E. S. (1969). Approximate randomization tests. The Journal of Psychology, 72(2), 143–149. https://doi.org/10.1080/00223980.1969.10543491Edgington, E. S. (1975). Randomization tests for one-subject operant experiments. Journal of Psychology, 90(1), 57. https://doi.org/10.1080/00223980.1975.9923926Edgington, E. S., & Onghena, P. (2007). Randomization tests (4th ed.). Chapman & Hall/CRC.Ferron, J., & Onghena, P. (1996). The power of randomization tests for single-case phase designs. Journal of Experimental Education, 64(3), 231–239. https://doi.org/10.1080/00220973.1996.9943805Ferron, J., & Sentovich, C. (2002). Statistical power of randomization tests used with multiple-baseline designs. Journal of Experimental Education, 70(2), 165–178. https://doi.org/10.1080/00220970209599504Ferron, J., & Ware, W. (1995). Analyzing single-case data: The power of randomization tests. The Journal of Experimental Education, 63(2), 167–178.Fisher, A. J., Medaglia, J. D., & Jeronimus, B. F. (2018). Lack of group-to-individual generalizability is a threat to human subjects research. Proceedings of the National Academy of Sciences, 115(27), E6106 LP-E6115. https://doi.org/10.1073/pnas.1711978115Foster, N. E., Anema, J. R., Cherkin, D., Chou, R., Cohen, S. P., Gross, D. P., Ferreira, P. H., Fritz, J. M., Koes, B. W., Peul, W., Turner, J. A., Maher, C. G., Buchbinder, R., Hartvigsen, J., Cherkin, D., Foster, N. E., Maher, C. G., Underwood, M., van Tulder, M., … Woolf, A. (2018). Prevention and treatment of low back pain: Evidence, challenges, and promising directions. The Lancet, 391(10137), 2368–2383. https://doi.org/10.1016/S0140-6736(18)30489-6Heyvaert, M., & Onghena, P. (2014a). Analysis of single-case data: Randomisation tests for measures of effect size. Neuropsychological Rehabilitation, 24(3–4), 507–527. https://doi.org/10.1080/09602011.2013.818564Heyvaert, M., & Onghena, P. (2014b). Randomization tests for single-case experiments: State of the art, state of the science, and state of the application. Journal of Contextual Behavioral Science, 3(1), 51–64. https://doi.org/10.1016/j.jcbs.2013.10.002Hope, A. C. A. (1968). A simplified Monte Carlo significance test procedure. Journal of the Royal Statistical Society. Series B (Methodological), 30(3), 582–598. http://www.jstor.org/stable/2984263Horner, R. H., Carr, E. G., Halle, J., Mcgee, G., Odom, S., & Wolery, M. (2005). The use of single-subject research to identify evidence-based practice in special education. Exceptional Children, 71(2), 165–179. https://doi.org/10.1177/001440290507100203Kazdin, A. E. (2011). Single-case research designs: Methods for clinical and applied settings (2nd ed.). Oxford University Press.Kratochwill, T. R., Hitchcock, J., Horner, R. H., Levin, J. R., Odom, S. L., Rindskopf, D. M., & Shadish, W. R. (2010). Single-case design technical documentation. https://ies.ed.gov/ncee/wwc/Docs/ReferenceResources/wwc_scd.pdfKratochwill, T. R., & Levin, J. R. (2010). Enhancing the scientific credibility of single-case intervention research: Randomization to the rescue. Psychological Methods, 15(2), 124–144. https://doi.org/10.1037/a0017736Levin, J. R., Ferron, J. M., & Gafurov, B. S. (2018). Comparison of randomization-test procedures for single-case multiple-baseline designs. Developmental Neurorehabilitation, 21(5), 290–311. https://doi.org/10.1080/17518423.2016.1197708Madden, V. J., Bellan, V., Russek, L. N., Camfferman, D., Vlaeyen, J. W. S., & Moseley, G. L. (2016). Pain by association? Experimental modulation of human pain thresholds using classical conditioning. Journal of Pain, 17(10), 1105–1115. https://doi.org/10.1016/j.jpain.2016.06.012Madden, V. J., Kamerman, P. R., Bellan, V., Catley, M. J., Russek, L. N., Camfferman, D., & Moseley, G. L. (2019). Was that painful or nonpainful? The Sensation and Pain Rating Scale performs well in the experimental context. Journal of Pain, 20(4), 472.e1-472.e12. https://doi.org/10.1016/j.jpain.2018.10.006Madden, V. J., Russek, L. N., Harvie, D. S., Vlaeyen, J. W. S., & Moseley, G. L. (2017). Classical conditioning fails to elicit allodynia in an experimental study with healthy humans. Pain Medicine, 18(7), 1314–1325. https://doi.org/10.1093/pm/pnw221Manolov, R., & Moeyaert, M. (2017). Recommendations for choosing single-case data analytical techniques. Behavior Therapy, 48(1), 97–114. https://doi.org/10.1016/j.beth.2016.04.008Manolov, R., & Solanas, A. (2018). Analytical options for single-case experimental designs: Review and application to brain impairment. Brain Impairment, 19(1), 18–32. https://doi.org/10.1017/BrImp.2017.17Matyas, T. A., & Greenwood, K. M. (1990). Visual analysis of single-case time series: Effects of variability, serial dependence, and magnitude of intervention effects. Journal of Applied Behavior Analysis, 23(3), 341–351. https://doi.org/10.1901/jaba.1990.23-341Michiels, B., Heyvaert, M., & Onghena, P. (2018). The conditional power of randomization tests for single-case effect sizes in designs with randomized treatment order: A Monte Carlo simulation study. Behavior Research Methods, 50(2), 557–575. https://doi.org/10.3758/s13428-017-0885-7Michiels, B., & Onghena, P. (2019). Randomized single-case AB phase designs: Prospects and pitfalls. Behavior Research Methods, 51(6), 2454–2476. https://doi.org/10.3758/s13428-018-1084-xMichiels, B., Tanious, R., De, T. K., & Onghena, P. (2020). A randomization test wrapper for synthesizing single-case experiments using multilevel models: A Monte Carlo simulation study. Behavior Research Methods, 52(2), 654–666. https://doi.org/10.3758/s13428-019-01266-6Molenaar, P. C. M., & Campbell, C. G. (2009). The new person-specific paradigm in psychology. Current Directions in Psychological Science, 18(2), 112–117. https://doi.org/10.1111/j.1467-8721.2009.01619.xMoseley, G. L., & Vlaeyen, J. W. S. (2015). Beyond nociception: The imprecision hypothesis of chronic pain. Pain, 156(1), 35–38. https://doi.org/10.1016/j.pain.0000000000000014Onghena, P. (1992). Randomization tests for extensions and variations of ABAB single-case experimental designs: A rejoinder. Behavioral Assessment, 14(2), 153–171.Onghena, P. (2005). Single‐case designs. In B. Everitt & D. Howell (Eds.), Encyclopedia of statistics in behavioral science (Vol. 4, pp. 1850–1854). John Wiley & Sons, Ltd. https://doi.org/10.1002/0470013192.bsa625Ottenbacher, K. J. (1990). When is a picture worth a thousand p values? A comparison of visual and quantitative methods to analyze single subject data. The Journal of Special Education, 23(4), 436–449. https://doi.org/10.1177/002246699002300407Pavlov, I. P. (1928). Lectures on conditioned reflexes: Twenty-five years of objective study of the higher nervous activity (behaviour) of animals. Liverwright Publishing Corporation. https://doi.org/10.1037/11081-000Smith, J. D. (2012). Single-case experimental designs: A systematic review of published research and current standards. Psychological Methods, 17(4), 510–550. https://doi.org/10.1037/a0029312Solomon, B. G. (2014). Violations of assumptions in school-based single-case data: Implications for the selection and interpretation of effect sizes. Behavior Modification, 38(4), 477–496. https://doi.org/10.1177/0145445513510931Spruyt, A., Clarysse, J., Vansteenwegen, D., Baeyens, F., & Hermans, D. (2009). Affect 4.0: A free software package for implementing psychological and psychophysiological experiments. Experimental Psychology, 57(1), 36–45. https://doi.org/10.1027/1618-3169/a000005Traxler, J., Madden, V. J., Moseley, G. L., & Vlaeyen, J. W. S. (2019). Modulating pain thresholds through classical conditioning. PeerJ, 2019(3), 1–20. https://doi.org/10.7717/peerj.6486Treede, R. D., Rief, W., Barke, A., Aziz, Q., Bennett, M. I., Benoliel, R., Cohen, M., Evers, S., Finnerup, N. B., First, M. B., Giamberardino, M. A., Kaasa, S., Korwisi, B., Kosek, E., Lavand’Homme, P., Nicholas, M., Perrot, S., Scholz, J., Schug, S., … Wang, S. J. (2019). Chronic pain as a symptom or a disease: The IASP classification of chronic pain for the International Classification of Diseases (ICD-11). Pain, 160(1), 19–27. https://doi.org/10.1097/j.pain.0000000000001384Tsang, A., Von Korff, M., Lee, S., Alonso, J., Karam, E., Angermeyer, M. C., Borges, G. L. G., Bromet, E. J., Demytteneare, K., de Girolamo, G., de Graaf, R., Gureje, O., Lepine, J.-P., Haro, J. M., Levinson, D., Oakley Browne, M. A., Posada-Villa, J., Seedat, S., & Watanabe, M. (2008). Common chronic pain conditions in developed and developing countries: Gender and age differences and comorbidity with depression-anxiety disorders. The Journal of Pain, 9(10), 883–891. https://doi.org/10.1016/j.jpain.2008.05.005Vlaeyen, J. W. S., & Linton, S. J. (2000). Fear-avoidance and its consequences in chronic musculoskeletal pain: A state of the art. Pain, 85(3), 317–332. https://doi.org/10.1016/s0304-3959(99)00242-0Vlaeyen, J. W. S., & Linton, S. J. (2012). Fear-avoidance model of chronic musculoskeletal pain: 12 years on. Pain, 153(6), 1144–1147. https://doi.org/10.1016/j.pain.2011.12.009Vlaeyen, J. W. S., Wicksell, R. K., Simons, L. E., Gentili, C., De, T. K., Tate, R. L., Vohra, S., Punja, S., Linton, S. J., Sniehotta, F. F., & Onghena, P. (2020). From Boulder to Stockholm in 70 years: Single case experimental designs in clinical research. The Psychological Record, 70, 659–670. https://doi.org/10.1007/s40732-020-00402-5Vohra, S., Shamseer, L., Sampson, M., Bukutu, C., Schmid, C. H., Tate, R., Nikles, J., Zucker, D. R., Kravitz, R., Guyatt, G., Altman, D. G., & Moher, D. (2015). CONSORT extension for reporting N-of-1 trials (CENT) 2015 statement. BMJ (Clinical Research Ed.), 350, h1738. https://doi.org/10.1136/bmj.h1738Willkinson, L. (1999). Statistical methods in psychology journals: Guidelines and explanations. American Psychologist, 54(8), 594–604. https://doi.org/10.1037/0003-066X.54.8.594Woolf, C. J. (1983). Evidence for a central component of post-injury pain hypersensitivity. Nature, 306(5944), 686–688. https://doi.org/10.1038/306686a0Woolf, C. J. (2011). Central sensitization: Implications for the diagnosis and treatment of pain. Pain, 152(3 Suppl), S2–S15. https://doi.org/10.1016/j.pain.2010.09.030AppendixTable 2Observed Scores From the Initial Nine Pilot Tests.P1V1P2V2P3V3P4V4P5V5P6V6P7V7P8V8P9V9A0A1A1A0ANAA-1A0A1A0A1A0A0A0A0A0A0A1A0A0A0A0A1A0A-1A0A1A0A0A0A0A1A0A1A0A1A-1A1A0A0A-1A0A0A0A0A0B1B0A0A0A0A0A0A-1A0B1B0ANAA0A0A0A0A0A0B0B0A1A0A0B0B0A0A1B0B-1A1A1A0B0B0A0A0B0B0A0A-1A0B0B0B1B0    B0B1B-1B0B0B0B0    BNAB0B0B0B0B0B0    BNAB0B0B0B0B0B0    B0B0B0B0B0B0B0    B0B0B0B0B0B1B-1    B0B-1B0    B0B1    B0B0B0    B0B0    B0B1B0    B1B0    BNAB0B0    B1B-1    B1B1B0    B1B0              B0B1              B0B1              B1B0              B1B0              B0B0              B1B0              B0B0              B0B0              B0B0Table 3Observed Scores From the Final Four Pilot Tests Formatted for Shiny SCDA.P10V10P11V11P12V12P13V13A1A0A0A0ANAA0A0A0A0A0A0A0A1A0A0A0A0A0A0A0A0A0A0A0A0A0A0A0A1A0A0A0A-1A0A0A0BNAB1B0B0B0B0B0B0BNAB1B0B0BNAB0B0B0BNAB1B0B0B0B0B0B0B0B1B0B0B0B1B0B0B0B1B0B0B0B1B0B0B0B1B0B0B0B1B0B0B0B0B0B0B0B0B0B0B0B1B0B0B0B0B0B0B0B0B0B0B0B0B0B0B0B0B0B0B0B0B0B0B0B0B0B0
  
randomized marker method PAGE   \* MERGEFORMAT 19COMPARISON OF STUDENT EVALUATIONS OF TEACHING PAGE   \* MERGEFORMAT 19
  
  